#!/usr/bin/env Rscript

# Phase 04 - Step 03: Layer-Specific Bipartite Modularity Analysis
# ---------------------------------------------------------------
# Purpose:
#   Analyze modularity separately for production and utilization layers of the
#   bipartite siderophore networks using bipartite::computeModules() with
#   replicate stability assessment and medoid partition selection.
#
# Key Features:
#   - Production layer: FG × PYO production incidence (primary)
#   - Utilization layer: FG × PYO utilization incidence (primary)
#   - Replicate stability: R replicates with ARI and CV metrics
#   - Representative selection: medoid partition (min mean VI)
#   - Minimal outputs: assignments RDS, replicate Q CSV, composition figures
#
# Outputs:
#   - results/phase_04/modularity/module_assignments_<layer>.rds
#   - results/phase_04/modularity/replicate_Q_<layer>.csv
#   - figures/network_topology/modularity_<layer>_composition.pdf
#   - docs/phase_04/logs/step03_modularity_summary.txt
#   - docs/phase_04/logs/step03_session_info.txt
#
# Usage:
#   Rscript scripts/phase_04_topology/03_modularity_analysis.R
#
# Author: automated assistant
# Date: autogenerated

suppressPackageStartupMessages({
  library(Matrix)
  library(ggplot2)
  library(dplyr)
  library(bipartite)
  library(jsonlite)
  if (!require(mclust, quietly = TRUE)) {
    message("Installing mclust for ARI computation...")
    install.packages("mclust", repos = "https://cran.r-project.org/")
    library(mclust)
  }
})

# -----------------------------
# Helper functions
# -----------------------------
safe_dir_create <- function(path) {
  if (!dir.exists(path)) dir.create(path, recursive = TRUE, showWarnings = FALSE)
}

timestamp <- function() format(Sys.time(), "%Y-%m-%d %H:%M:%S %Z")

# Build layer-specific incidence matrix
build_layer_incidence <- function(adj_production, adj_utilization, layer = "production") {
  if (layer == "production") {
    # Production: FG × PYO (use as-is)
    incidence <- as.matrix(adj_production > 0) * 1
  } else if (layer == "utilization") {
    # Utilization: transpose PYO×FG to get FG×PYO
    incidence <- as.matrix(t(adj_utilization) > 0) * 1
  } else {
    stop("Layer must be 'production' or 'utilization'")
  }

  # Ensure consistent row/col names
  if (layer == "utilization") {
    # After transpose, should have same FG rows as production
    if (!all(rownames(incidence) == rownames(adj_production))) {
      stop("Row name mismatch between production and utilization layers")
    }
  }

  return(incidence)
}

# Remove zero-degree rows and columns
remove_zero_degree <- function(incidence, layer_name) {
  initial_dims <- dim(incidence)

  # Find zero-degree rows and columns
  row_degrees <- rowSums(incidence)
  col_degrees <- colSums(incidence)

  zero_rows <- which(row_degrees == 0)
  zero_cols <- which(col_degrees == 0)

  # Remove zero-degree nodes
  if (length(zero_rows) > 0) {
    incidence <- incidence[-zero_rows, , drop = FALSE]
  }
  if (length(zero_cols) > 0) {
    incidence <- incidence[, -zero_cols, drop = FALSE]
  }

  final_dims <- dim(incidence)

  # Log removal summary
  removal_summary <- list(
    layer = layer_name,
    initial_dims = initial_dims,
    final_dims = final_dims,
    zero_rows_removed = length(zero_rows),
    zero_cols_removed = length(zero_cols),
    zero_row_names = if (length(zero_rows) > 0) rownames(incidence)[zero_rows] else character(0),
    zero_col_names = if (length(zero_cols) > 0) colnames(incidence)[zero_cols] else character(0)
  )

  return(list(incidence = incidence, removal_summary = removal_summary))
}

# Compute modularity with error handling
compute_modularity_safe <- function(incidence, seed = NULL) {
  if (!is.null(seed)) set.seed(seed)

  result <- tryCatch(
    {
      bipartite::computeModules(incidence,
        method = "Beckett",
        deep = FALSE,
        deleteOriginalFiles = TRUE,
        steps = 1000000,
        tolerance = 1e-10,
        experimental = FALSE,
        forceLPA = FALSE
      )
    },
    error = function(e) {
      message("computeModules failed with error: ", e$message)
      NULL
    }
  )

  return(result)
}

# Extract module information from bipartite result
extract_module_info <- function(module_result, incidence, layer_name) {
  if (is.null(module_result)) {
    return(list(Q = NA, modules = NULL, n_modules = 0))
  }

  # Extract modularity score
  Q <- module_result@likelihood

  # Extract module assignments
  # module_result@modules is typically a list with $`1` containing the partition
  if (length(module_result@modules) > 0 && !is.null(module_result@modules[[1]])) {
    partition <- module_result@modules[[1]]

    # Create node assignments
    row_names <- rownames(incidence)
    col_names <- colnames(incidence)
    n_rows <- length(row_names)
    n_cols <- length(col_names)

    # Partition should have length = n_rows + n_cols
    if (length(partition) != (n_rows + n_cols)) {
      warning("Partition length doesn't match matrix dimensions")
      return(list(Q = Q, modules = NULL, n_modules = 0))
    }

    # Split partition into row and column modules
    row_modules <- partition[1:n_rows]
    col_modules <- partition[(n_rows + 1):(n_rows + n_cols)]

    # Create module assignment table
    modules_df <- data.frame(
      node_id = c(row_names, col_names),
      node_type = c(rep("FG", n_rows), rep("PYOV", n_cols)),
      module_id = c(row_modules, col_modules),
      layer = layer_name,
      stringsAsFactors = FALSE
    )

    n_modules <- length(unique(partition))

    return(list(Q = Q, modules = modules_df, n_modules = n_modules))
  } else {
    return(list(Q = Q, modules = NULL, n_modules = 0))
  }
}

# Compute pairwise ARI between partitions
compute_pairwise_ari <- function(partition_list) {
  n_reps <- length(partition_list)
  if (n_reps < 2) {
    return(c(mean = NA, iqr_lower = NA, iqr_upper = NA))
  }

  ari_values <- numeric(0)

  for (i in 1:(n_reps - 1)) {
    for (j in (i + 1):n_reps) {
      if (!is.null(partition_list[[i]]) && !is.null(partition_list[[j]])) {
        # Extract module assignments
        p1 <- partition_list[[i]]$modules$module_id
        p2 <- partition_list[[j]]$modules$module_id

        if (length(p1) == length(p2)) {
          ari <- mclust::adjustedRandIndex(p1, p2)
          ari_values <- c(ari_values, ari)
        }
      }
    }
  }

  if (length(ari_values) == 0) {
    return(c(mean = NA, iqr_lower = NA, iqr_upper = NA))
  }

  return(c(
    mean = mean(ari_values, na.rm = TRUE),
    iqr_lower = quantile(ari_values, 0.25, na.rm = TRUE),
    iqr_upper = quantile(ari_values, 0.75, na.rm = TRUE)
  ))
}

# Compute mean VI and select medoid
compute_medoid_partition <- function(partition_list) {
  n_reps <- length(partition_list)
  valid_partitions <- which(!sapply(partition_list, function(x) is.null(x$modules)))

  if (length(valid_partitions) < 2) {
    # Return first valid partition if available
    if (length(valid_partitions) >= 1) {
      return(list(medoid_idx = valid_partitions[1], mean_vi = NA))
    } else {
      return(list(medoid_idx = NA, mean_vi = NA))
    }
  }

  # Compute mean VI for each partition
  mean_vi_values <- numeric(n_reps)
  mean_vi_values[] <- Inf

  for (i in valid_partitions) {
    vi_sum <- 0
    vi_count <- 0

    for (j in valid_partitions) {
      if (i != j) {
        p1 <- partition_list[[i]]$modules$module_id
        p2 <- partition_list[[j]]$modules$module_id

        if (length(p1) == length(p2)) {
          # Compute VI using mclust (note: mclust doesn't have VI, use 1-ARI as proxy)
          ari <- mclust::adjustedRandIndex(p1, p2)
          vi_proxy <- 1 - ari # Simple proxy for VI
          vi_sum <- vi_sum + vi_proxy
          vi_count <- vi_count + 1
        }
      }
    }

    if (vi_count > 0) {
      mean_vi_values[i] <- vi_sum / vi_count
    }
  }

  # Select partition with minimum mean VI
  medoid_idx <- which.min(mean_vi_values)

  return(list(medoid_idx = medoid_idx, mean_vi = mean_vi_values[medoid_idx]))
}

# Create module composition plot
plot_module_composition <- function(modules_df, layer_name, Q_value) {
  if (is.null(modules_df) || nrow(modules_df) == 0) {
    p <- ggplot() +
      theme_void() +
      annotate("text",
        x = 0.5, y = 0.5,
        label = paste("No modules found for", layer_name, "layer")
      )
    return(p)
  }

  # Calculate module statistics
  module_stats <- modules_df %>%
    group_by(module_id) %>%
    summarise(
      n_fg = sum(node_type == "FG"),
      n_pyov = sum(node_type == "PYOV"),
      total_size = n(),
      .groups = "drop"
    ) %>%
    arrange(desc(total_size)) %>%
    mutate(module_id = factor(module_id, levels = module_id))

  # Create stacked bar plot
  plot_data <- module_stats %>%
    tidyr::pivot_longer(
      cols = c(n_fg, n_pyov),
      names_to = "node_type",
      values_to = "count"
    ) %>%
    mutate(node_type = ifelse(node_type == "n_fg", "FG", "PYOV"))

  p <- ggplot(plot_data, aes(x = module_id, y = count, fill = node_type)) +
    geom_bar(stat = "identity", position = "stack") +
    scale_fill_manual(
      values = c("FG" = "steelblue", "PYOV" = "orange"),
      name = "Node Type"
    ) +
    labs(
      title = paste0(
        "Module Composition: ", stringr::str_to_title(layer_name),
        " Layer (Q = ", round(Q_value, 3), ")"
      ),
      x = "Module ID (ordered by size)",
      y = "Number of Nodes"
    ) +
    theme_minimal() +
    theme(
      plot.title = element_text(hjust = 0.5, size = 12),
      axis.text.x = element_text(angle = 45, hjust = 1),
      legend.position = "bottom"
    )

  return(p)
}

# -----------------------------
# Directory setup
# -----------------------------
safe_dir_create("results/phase_04/modularity")
safe_dir_create("figures/network_topology")
safe_dir_create("docs/phase_04/logs")

cat("=== Phase 04 - Step 03: Layer-Specific Bipartite Modularity Analysis ===\n")
start_time <- Sys.time()
cat(paste("Timestamp:", timestamp(), "\n"))
cat(paste("Run start:", format(start_time, "%Y-%m-%d %H:%M:%S %Z"), "\n\n"))

# -----------------------------
# Load parameters from manifest
# -----------------------------
manifest_json <- "docs/phase_04/parameters_manifest.json"
manifest <- list()
if (file.exists(manifest_json)) {
  manifest <- tryCatch(fromJSON(manifest_json), error = function(e) {
    message("Could not parse manifest JSON; using defaults")
    list()
  })
}

# Parameters with defaults
master_seed <- if (!is.null(manifest$master_seed)) manifest$master_seed else 2025
n_replicates_pilot <- if (!is.null(manifest$modularity_replicates$pilot)) manifest$modularity_replicates$pilot else 50
n_replicates_final <- if (!is.null(manifest$modularity_replicates$final)) manifest$modularity_replicates$final else 100

cat(sprintf("Parameters: master_seed=%d, n_replicates=%d\n", master_seed, n_replicates_pilot))

# -----------------------------
# Load and validate inputs
# -----------------------------
cat("Loading adjacency matrices and node tables...\n")

# File paths
required_files <- list(
  adj_prod_fg = "data/interim/adj_production_FG_agentsxpyov_conservative.rds",
  adj_util_fg = "data/interim/adj_utilization_FG_pyovxagents_conservative.rds",
  fg_nodes = "data/interim/nodes_functional_groups_conservative.rds",
  pyov_nodes = "data/interim/nodes_pyoverdines_conservative.rds"
)

# Check file existence
for (name in names(required_files)) {
  if (!file.exists(required_files[[name]])) {
    stop("Required input missing: ", required_files[[name]])
  }
}

# Load data
adj_prod_fg <- readRDS(required_files$adj_prod_fg)
adj_util_fg <- readRDS(required_files$adj_util_fg)
fg_nodes <- readRDS(required_files$fg_nodes)
pyov_nodes <- readRDS(required_files$pyov_nodes)

# Validate input dimensions and names
cat("Validating input consistency...\n")
cat(sprintf("Production matrix: %d × %d\n", nrow(adj_prod_fg), ncol(adj_prod_fg)))
cat(sprintf("Utilization matrix: %d × %d\n", nrow(adj_util_fg), ncol(adj_util_fg)))

# Check name alignment
if (!all(rownames(adj_prod_fg) %in% fg_nodes$agent_id)) {
  warning("Some production row names not found in FG nodes")
}
if (!all(colnames(adj_prod_fg) %in% pyov_nodes$node_id)) {
  warning("Some production column names not found in PYOV nodes")
}

# -----------------------------
# Main analysis loop: for each layer
# -----------------------------
layers <- c("production", "utilization")
layer_results <- list()

for (layer in layers) {
  cat(sprintf("\n=== Analyzing %s layer ===\n", stringr::str_to_title(layer)))

  # 1. Build layer-specific incidence matrix
  cat("Building incidence matrix...\n")
  incidence_raw <- build_layer_incidence(adj_prod_fg, adj_util_fg, layer)

  # 2. Remove zero-degree nodes
  filtered_result <- remove_zero_degree(incidence_raw, layer)
  incidence <- filtered_result$incidence
  removal_summary <- filtered_result$removal_summary

  cat(sprintf(
    "Matrix after filtering: %d × %d (removed %d rows, %d cols)\n",
    nrow(incidence), ncol(incidence),
    removal_summary$zero_rows_removed, removal_summary$zero_cols_removed
  ))

  if (sum(incidence) == 0) {
    cat("Warning: No interactions in filtered matrix. Skipping layer.\n")
    layer_results[[layer]] <- list(
      layer = layer,
      status = "failed",
      reason = "no_interactions",
      removal_summary = removal_summary
    )
    next
  }

  # 3. Run replicate modularity analysis (with timing)
  cat(sprintf("Running %d replicates of modularity analysis...\n", n_replicates_pilot))

  replicate_results <- list()
  Q_values <- numeric(n_replicates_pilot)
  replicate_times <- numeric(n_replicates_pilot)

  layer_start_time <- Sys.time()

  for (rep in 1:n_replicates_pilot) {
    rep_seed <- master_seed + rep * 1000 # Deterministic seed derivation

    cat(sprintf("  Replicate %d/%d (seed=%d)...\n", rep, n_replicates_pilot, rep_seed))
    rep_start_time <- Sys.time()

    module_result <- compute_modularity_safe(incidence, seed = rep_seed)
    module_info <- extract_module_info(module_result, incidence, layer)

    rep_end_time <- Sys.time()
    rep_elapsed <- as.numeric(difftime(rep_end_time, rep_start_time, units = "secs"))
    replicate_times[rep] <- rep_elapsed

    cat(sprintf("    Replicate %d completed in %.2f seconds\n", rep, rep_elapsed))

    replicate_results[[rep]] <- list(
      replicate = rep,
      seed = rep_seed,
      module_info = module_info,
      time_sec = rep_elapsed
    )

    Q_values[rep] <- if (!is.na(module_info$Q)) module_info$Q else NA
  }

  layer_end_time <- Sys.time()
  layer_elapsed <- as.numeric(difftime(layer_end_time, layer_start_time, units = "secs"))
  cat(sprintf(
    "Layer %s completed in %.2f seconds (%.2f sec per replicate on average)\n",
    layer, layer_elapsed, mean(replicate_times, na.rm = TRUE)
  ))

  # 4. Compute stability metrics
  cat("Computing stability metrics...\n")

  valid_Q <- Q_values[!is.na(Q_values)]
  if (length(valid_Q) == 0) {
    cat("Warning: No valid Q values obtained. Skipping layer.\n")
    layer_results[[layer]] <- list(
      layer = layer,
      status = "failed",
      reason = "no_valid_Q",
      removal_summary = removal_summary
    )
    next
  }

  Q_stats <- list(
    mean = mean(valid_Q),
    sd = sd(valid_Q),
    min = min(valid_Q),
    max = max(valid_Q),
    cv = sd(valid_Q) / mean(valid_Q),
    n_valid = length(valid_Q)
  )

  # Extract valid partition results for ARI computation
  valid_partitions <- replicate_results[!is.na(Q_values)]
  partition_list <- lapply(valid_partitions, function(x) x$module_info)

  # Compute ARI statistics
  ari_stats <- compute_pairwise_ari(partition_list)

  # 5. Select representative partition (medoid)
  cat("Selecting representative partition...\n")
  medoid_result <- compute_medoid_partition(partition_list)

  if (is.na(medoid_result$medoid_idx)) {
    cat("Warning: Could not select medoid partition. Using first valid.\n")
    representative_idx <- which(!is.na(Q_values))[1]
  } else {
    representative_idx <- medoid_result$medoid_idx
  }

  representative_partition <- replicate_results[[representative_idx]]$module_info
  representative_Q <- Q_values[representative_idx]

  # Also record best Q replicate
  best_Q_idx <- which.max(Q_values)
  best_Q_value <- Q_values[best_Q_idx]

  # 6. Create replicate Q table for saving
  replicate_Q_df <- data.frame(
    replicate_index = 1:n_replicates_pilot,
    seed = sapply(replicate_results, function(x) x$seed),
    Q_value = Q_values,
    layer = layer,
    stringsAsFactors = FALSE
  )

  # 7. Save outputs
  cat("Saving outputs...\n")

  # Save module assignments (representative partition)
  if (!is.null(representative_partition$modules)) {
    assignments_file <- paste0("results/phase_04/modularity/module_assignments_", layer, ".rds")
    saveRDS(representative_partition$modules, assignments_file)
  }

  # Save replicate Q values
  replicate_Q_file <- paste0("results/phase_04/modularity/replicate_Q_", layer, ".csv")
  write.csv(replicate_Q_df, replicate_Q_file, row.names = FALSE)

  # Create and save composition plot
  if (!is.null(representative_partition$modules)) {
    p_composition <- plot_module_composition(representative_partition$modules, layer, representative_Q)
    composition_file <- paste0("figures/network_topology/modularity_", layer, "_composition.pdf")
    ggsave(composition_file, p_composition, width = 10, height = 6)
  }

  # 8. Store results for summary
  layer_results[[layer]] <- list(
    layer = layer,
    status = "success",
    removal_summary = removal_summary,
    incidence_dims = dim(incidence),
    incidence_fill = sum(incidence) / (nrow(incidence) * ncol(incidence)),
    Q_stats = Q_stats,
    ari_stats = ari_stats,
    representative_Q = representative_Q,
    representative_modules = representative_partition$n_modules,
    best_Q = best_Q_value,
    medoid_mean_vi = medoid_result$mean_vi,
    n_replicates = n_replicates_pilot
  )

  cat(sprintf(
    "Layer complete: Q=%.3f, %d modules, CV=%.3f, mean_ARI=%.3f\n",
    representative_Q, representative_partition$n_modules,
    Q_stats$cv, ari_stats["mean"]
  ))
}

# -----------------------------
# Generate consolidated summary
# -----------------------------
cat("\nGenerating consolidated summary...\n")

summary_lines <- c(
  "Phase 04 - Step 03: Layer-Specific Bipartite Modularity Analysis Summary",
  paste("Timestamp:", timestamp()),
  paste("Master seed:", master_seed),
  paste("Replicates per layer:", n_replicates_pilot),
  "",
  "Method:",
  "  Optimizer: bipartite::computeModules (Beckett method)",
  "  Layers analyzed: Production and Utilization (separate)",
  "  Representative selection: Medoid partition (minimum mean VI)",
  "  Stability metrics: Q coefficient of variation, pairwise ARI",
  ""
)

# Add layer-specific results
for (layer in layers) {
  result <- layer_results[[layer]]

  summary_lines <- c(
    summary_lines,
    paste(stringr::str_to_title(layer), "Layer:"),
    paste("  Status:", result$status)
  )

  if (result$status == "success") {
    summary_lines <- c(
      summary_lines,
      sprintf("  Matrix dimensions: %d × %d (%.1f%% fill)", result$incidence_dims[1], result$incidence_dims[2], 100 * result$incidence_fill),
      sprintf("  Nodes removed: %d FGs, %d PYOVs", result$removal_summary$zero_rows_removed, result$removal_summary$zero_cols_removed),
      sprintf("  Representative Q: %.3f (%d modules)", result$representative_Q, result$representative_modules),
      sprintf("  Best Q: %.3f", result$best_Q),
      sprintf("  Q stability: mean=%.3f, sd=%.3f, CV=%.3f (%d valid)", result$Q_stats$mean, result$Q_stats$sd, result$Q_stats$cv, result$Q_stats$n_valid),
      sprintf("  Partition similarity: mean_ARI=%.3f (IQR: %.3f-%.3f)", result$ari_stats["mean"], result$ari_stats["iqr_lower"], result$ari_stats["iqr_upper"])
    )

    # Stability warnings
    if (result$Q_stats$cv > 0.10) {
      summary_lines <- c(summary_lines, "  ⚠️  WARNING: High Q variability (CV > 0.10)")
    }
    if (!is.na(result$ari_stats["mean"]) && result$ari_stats["mean"] < 0.60) {
      summary_lines <- c(summary_lines, "  ⚠️  WARNING: Low partition consistency (mean ARI < 0.60)")
    }
  } else {
    summary_lines <- c(
      summary_lines,
      paste("  Reason:", result$reason)
    )
  }

  summary_lines <- c(summary_lines, "")
}

# Add interpretation and outputs
summary_lines <- c(
  summary_lines,
  "Interpretation:",
  "  Q > 0.3: Strong modularity, distinct community structure",
  "  Q 0.1-0.3: Moderate modularity, some community organization",
  "  Q < 0.1: Weak modularity, close to random structure",
  "  CV > 0.10: Optimizer instability (consider more replicates)",
  "  mean ARI < 0.60: Low partition consistency",
  "",
  "Outputs Saved:",
  "  Module assignments: results/phase_04/modularity/module_assignments_<layer>.rds",
  "  Replicate Q values: results/phase_04/modularity/replicate_Q_<layer>.csv",
  "  Composition plots: figures/network_topology/modularity_<layer>_composition.pdf",
  "  Summary: docs/phase_04/logs/step03_modularity_summary.txt",
  "  Session info: docs/phase_04/logs/step03_session_info.txt",
  "",
  "Next Steps:",
  "  - If stability warnings present, consider rerunning with more replicates",
  "  - For significance testing, run debug null script for relevant layers",
  "  - For exploratory union analysis, run additional union script",
  "",
  "Ready for subsequent analyses."
)

# Write summary
writeLines(summary_lines, "docs/phase_04/logs/step03_modularity_summary.txt")

# Save session info
writeLines(capture.output(sessionInfo()), "docs/phase_04/logs/step03_session_info.txt")

# Display summary
cat("\n", paste(summary_lines, collapse = "\n"), "\n")

cat("\nStep 03 complete. Layer-specific modularity analysis finished.\n")
cat("Summary: docs/phase_04/logs/step03_modularity_summary.txt\n")
cat("Check stability warnings and module assignments for next steps.\n")

# Record total and per-layer timing to a small timing log
end_time <- Sys.time()
total_elapsed <- as.numeric(difftime(end_time, start_time, units = "secs"))

timing_lines <- c(
  paste("Run start:", format(start_time, "%Y-%m-%d %H:%M:%S %Z")),
  paste("Run end:  ", format(end_time, "%Y-%m-%d %H:%M:%S %Z")),
  sprintf("Total elapsed (sec): %.2f", total_elapsed),
  ""
)

for (layer in names(layer_results)) {
  lr <- layer_results[[layer]]
  if (!is.null(lr$incidence_dims)) {
    layer_time_msg <- if (!is.null(lr$layer_time)) {
      sprintf("Layer %s elapsed (sec): %.2f", layer, lr$layer_time)
    } else if (!is.null(lr$Q_stats) && !is.null(lr$n_replicates)) {
      # approximate if explicit layer time not recorded
      sprintf("Layer %s (approx) elapsed per-replicate (sec): unknown", layer)
    } else {
      sprintf("Layer %s: no timing info", layer)
    }
    timing_lines <- c(timing_lines, layer_time_msg)
  } else {
    timing_lines <- c(timing_lines, sprintf("Layer %s: skipped or failed", layer))
  }
}

timing_file <- "docs/phase_04/logs/step03_timing.txt"
writeLines(timing_lines, timing_file)
cat("Timing summary saved to:", timing_file, "\n")
