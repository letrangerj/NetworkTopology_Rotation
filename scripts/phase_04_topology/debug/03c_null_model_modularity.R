#!/usr/bin/env Rscript

# Phase 04 - Step 03c: Layer-Specific Null Model Modularity Test (Debug/Logs-Only)
# ------------------------------------------------------------------------------
# Purpose:
#   Test statistical significance of observed modularity for production and
#   utilization layers using degree-preserving bipartite null models.
#
# Method:
#   - Accept layer argument (production or utilization) or run both serially
#   - Generate N degree-preserving nulls based on manifest parameters
#   - For each null, compute modularity Q via computeModules() (single run)
#   - Report null summary statistics, two-tailed p-value (+1 correction), SES
#   - Include comprehensive stability assessment (R=20 for observed, sample for nulls)
#   - Save only text summary (no RDS/figures) in debug logs
#
# Usage:
#   Rscript scripts/phase_04_topology/debug/03c_null_model_modularity.R --layer production
#   Rscript scripts/phase_04_topology/debug/03c_null_model_modularity.R --layer utilization
#   Rscript scripts/phase_04_topology/debug/03c_null_model_modularity.R  # runs both layers
#   Rscript scripts/phase_04_topology/debug/03c_null_model_modularity.R --pilot  # use pilot null count
#   Rscript scripts/phase_04_topology/debug/03c_null_model_modularity.R --final  # use final null count
#
# Author: automated assistant
# Date: autogenerated

suppressPackageStartupMessages({
  library(Matrix)
  library(ggplot2)
  library(dplyr)
  library(bipartite)
  library(vegan)
  library(jsonlite)
  library(stringr)
  library(mclust)
})

# -----------------------------
# Helper functions
# -----------------------------
safe_dir_create <- function(path) {
  if (!dir.exists(path)) dir.create(path, recursive = TRUE, showWarnings = FALSE)
}

timestamp <- function() format(Sys.time(), "%Y-%m-%d %H:%M:%S %Z")

# Build layer-specific incidence matrix
build_layer_incidence <- function(adj_production, adj_utilization, layer = "production") {
  if (layer == "production") {
    incidence <- as.matrix(adj_production > 0) * 1
  } else if (layer == "utilization") {
    incidence <- as.matrix(t(adj_utilization) > 0) * 1
  } else {
    stop("Layer must be 'production' or 'utilization'")
  }
  return(incidence)
}

# Remove zero-degree rows and columns
remove_zero_degree <- function(incidence, layer_name) {
  initial_dims <- dim(incidence)

  row_degrees <- rowSums(incidence)
  col_degrees <- colSums(incidence)

  zero_rows <- which(row_degrees == 0)
  zero_cols <- which(col_degrees == 0)

  if (length(zero_rows) > 0) {
    incidence <- incidence[-zero_rows, , drop = FALSE]
  }
  if (length(zero_cols) > 0) {
    incidence <- incidence[, -zero_cols, drop = FALSE]
  }

  final_dims <- dim(incidence)

  removal_summary <- list(
    layer = layer_name,
    initial_dims = initial_dims,
    final_dims = final_dims,
    zero_rows_removed = length(zero_rows),
    zero_cols_removed = length(zero_cols)
  )

  return(list(incidence = incidence, removal_summary = removal_summary))
}

# Compute modularity with error handling - EXACTLY matches main function parameters
compute_modularity_safe <- function(incidence, seed = NULL) {
  if (!is.null(seed)) set.seed(seed)

  result <- tryCatch(
    {
      bipartite::computeModules(incidence,
        method = "Beckett",
        deep = FALSE,
        deleteOriginalFiles = TRUE,
        steps = 1000000,
        tolerance = 1e-10,
        experimental = FALSE,
        forceLPA = FALSE
      )
    },
    error = function(e) {
      message("computeModules failed with error: ", e$message)
      NULL
    }
  )

  return(result)
}

# Extract Q value from bipartite result
extract_Q_value <- function(module_result) {
  if (is.null(module_result)) {
    return(NA_real_)
  }

  Q <- module_result@likelihood
  return(Q)
}

# Compute ARI between partitions
compute_partition_ari <- function(partition1, partition2) {
  if (length(partition1) != length(partition2)) {
    return(NA_real_)
  }
  return(as.numeric(mclust::adjustedRandIndex(partition1, partition2)))
}

# Extract module assignments from bipartite result (S4 object correct access)
extract_module_assignments <- function(module_result, incidence) {
  if (is.null(module_result)) {
    return(NULL)
  }

  # Correct S4 object access for bipartite results
  if (!is.null(module_result@modules) &&
    length(module_result@modules) > 0 &&
    !is.null(module_result@modules[[1]])) {
    partition <- module_result@modules[[1]]

    # Validate partition dimensions
    row_names <- rownames(incidence)
    col_names <- colnames(incidence)
    n_rows <- length(row_names)
    n_cols <- length(col_names)

    if (length(partition) != (n_rows + n_cols)) {
      return(NULL)
    }

    # Return partition vector for ARI computation
    return(partition)
  }

  return(NULL)
}

# Compute null distribution stability metrics
compute_null_stability <- function(incidence, n_stability_reps = 5, master_seed) {
  Q_values <- numeric(n_stability_reps)
  partition_list <- list()

  for (rep in 1:n_stability_reps) {
    rep_seed <- master_seed + rep * 10000

    # Compute modularity with deterministic seed
    module_result <- compute_modularity_safe(incidence, seed = rep_seed)
    Q_values[rep] <- extract_Q_value(module_result)

    # Extract partition assignment
    partition <- extract_module_assignments(module_result, incidence)
    if (!is.null(partition)) {
      partition_list[[rep]] <- partition
    }
  }

  # Compute stability metrics
  valid_Q <- Q_values[!is.na(Q_values)]
  if (length(valid_Q) == 0) {
    return(list(
      n_valid = 0,
      mean_Q = NA_real_,
      sd_Q = NA_real_,
      CV = NA_real_,
      mean_ARI = NA_real_,
      ari_iqr_lower = NA_real_,
      ari_iqr_upper = NA_real_
    ))
  }

  # Compute ARI stability between partitions
  ari_values <- numeric(0)
  valid_partitions <- which(!sapply(partition_list, is.null))

  if (length(valid_partitions) >= 2) {
    for (i in 1:(length(valid_partitions) - 1)) {
      for (j in (i + 1):length(valid_partitions)) {
        ari <- compute_partition_ari(
          partition_list[[valid_partitions[i]]],
          partition_list[[valid_partitions[j]]]
        )
        if (!is.na(ari)) {
          ari_values <- c(ari_values, ari)
        }
      }
    }
  }

  mean_ari <- if (length(ari_values) > 0) mean(ari_values, na.rm = TRUE) else NA_real_
  ari_iqr <- if (length(ari_values) > 0) {
    quantile(ari_values, probs = c(0.25, 0.75), na.rm = TRUE)
  } else {
    c(NA_real_, NA_real_)
  }

  return(list(
    n_valid = length(valid_Q),
    mean_Q = mean(valid_Q),
    sd_Q = sd(valid_Q),
    CV = ifelse(mean(valid_Q) > 0, sd(valid_Q) / mean(valid_Q), NA_real_),
    mean_ARI = mean_ari,
    ari_iqr_lower = ari_iqr[1],
    ari_iqr_upper = ari_iqr[2]
  ))
}

# Enhanced observed stability function with ARI computation
compute_observed_stability <- function(incidence, master_seed, layer) {
  cat("Computing observed stability metrics (R=20)...\n")

  R_stability <- 20
  Q_values <- numeric(R_stability)
  partition_list <- list()

  for (rep in 1:R_stability) {
    rep_seed <- master_seed + rep * 1000

    # Compute modularity and store both Q and partition
    module_result <- compute_modularity_safe(incidence, seed = rep_seed)
    Q_values[rep] <- extract_Q_value(module_result)

    # Store partition if modules found (consistent with extract_module_assignments validation)
    partition <- extract_module_assignments(module_result, incidence)
    if (!is.null(partition)) {
      partition_list[[rep]] <- partition
    } else {
      partition_list[[rep]] <- NULL
    }
  }

  # Compute Q statistics
  valid_Q <- Q_values[!is.na(Q_values)]
  if (length(valid_Q) == 0) {
    return(list(
      n_valid = 0,
      mean_Q = NA_real_,
      sd_Q = NA_real_,
      CV = NA_real_,
      mean_ARI = NA_real_,
      ari_iqr_lower = NA_real_,
      ari_iqr_upper = NA_real_
    ))
  }

  # Compute ARI between all pairs of partitions
  ari_values <- numeric(0)
  valid_partitions <- which(!sapply(partition_list, is.null))

  if (length(valid_partitions) >= 2) {
    for (i in 1:(length(valid_partitions) - 1)) {
      for (j in (i + 1):length(valid_partitions)) {
        ari <- compute_partition_ari(
          partition_list[[valid_partitions[i]]],
          partition_list[[valid_partitions[j]]]
        )
        if (!is.na(ari)) {
          ari_values <- c(ari_values, ari)
        }
      }
    }
  }

  mean_ari <- if (length(ari_values) > 0) mean(ari_values, na.rm = TRUE) else NA_real_
  ari_iqr <- if (length(ari_values) > 0) {
    quantile(ari_values, probs = c(0.25, 0.75), na.rm = TRUE)
  } else {
    c(NA_real_, NA_real_)
  }

  return(list(
    n_valid = length(valid_Q),
    mean_Q = mean(valid_Q),
    sd_Q = sd(valid_Q),
    CV = ifelse(mean(valid_Q) > 0, sd(valid_Q) / mean(valid_Q), NA_real_),
    mean_ARI = mean_ari,
    ari_iqr_lower = ari_iqr[1],
    ari_iqr_upper = ari_iqr[2]
  ))
}



# -----------------------------
# Command line argument parsing
# -----------------------------
args <- commandArgs(trailingOnly = TRUE)

# Parse layer arguments
layer_args <- args[!args %in% c("--pilot", "--final")]
param_args <- args[args %in% c("--pilot", "--final")]

if (length(layer_args) == 0) {
  run_both <- TRUE
  target_layer <- NULL
} else if (length(layer_args) == 1 && layer_args[1] %in% c("production", "utilization")) {
  run_both <- FALSE
  target_layer <- layer_args[1]
} else {
  stop("Usage: Rscript 03c_null_model_modularity.R [--layer production|utilization] [--pilot|--final]")
}

layers_to_run <- if (run_both) c("production", "utilization") else target_layer

# -----------------------------
# Directory setup
# -----------------------------
safe_dir_create("scripts/phase_04_topology/debug/logs")

cat("=== Phase 04 - Step 03c: Layer-Specific Null Model Modularity Test ===\n")
cat(paste("Timestamp:", timestamp(), "\n"))
cat(sprintf("Layers to test: %s\n", paste(layers_to_run, collapse = ", ")))

# -----------------------------
# Load parameters from manifest
# -----------------------------
manifest_json <- "docs/phase_04/parameters_manifest.json"
manifest <- list()
if (file.exists(manifest_json)) {
  manifest <- tryCatch(fromJSON(manifest_json), error = function(e) {
    message("Could not parse manifest JSON; using defaults")
    list()
  })
}

master_seed <- if (!is.null(manifest$master_seed)) manifest$master_seed else 2025

# Parameter selection: allow pilot vs final null model runs
use_final_params <- "--final" %in% param_args
use_pilot_params <- "--pilot" %in% param_args

# Default: use pilot parameters for quick testing
if (use_final_params) {
  n_nulls <- if (!is.null(manifest$null_model_N[["final"]])) manifest$null_model_N[["final"]] else 1000
  param_mode <- "final (full inference)"
} else if (use_pilot_params) {
  n_nulls <- if (!is.null(manifest$null_model_N[["pilot"]])) manifest$null_model_N[["pilot"]] else 100
  param_mode <- "pilot (quick testing)"
} else {
  # Default to pilot for debugging, but inform user
  n_nulls <- if (!is.null(manifest$null_model_N[["pilot"]])) manifest$null_model_N[["pilot"]] else 100
  param_mode <- "pilot (default - use --pilot or --final to specify)"
}

cat(sprintf("Parameters: master_seed=%d, n_nulls=%d (%s)\n", master_seed, n_nulls, param_mode))

# -----------------------------
# Load and validate inputs
# -----------------------------
cat("Loading adjacency matrices...\n")

required_files <- list(
  adj_prod_fg = "data/interim/adj_production_FG_agentsxpyov_conservative.rds",
  adj_util_fg = "data/interim/adj_utilization_FG_pyovxagents_conservative.rds"
)

for (name in names(required_files)) {
  if (!file.exists(required_files[[name]])) {
    stop("Required input missing: ", required_files[[name]])
  }
}

adj_prod_fg <- readRDS(required_files$adj_prod_fg)
adj_util_fg <- readRDS(required_files$adj_util_fg)

# -----------------------------
# Process each layer
# -----------------------------
all_results <- list()

for (layer in layers_to_run) {
  cat(sprintf("\n=== Testing %s layer ===\n", stringr::str_to_title(layer)))

  layer_start_time <- Sys.time()

  # 1. Build and filter incidence matrix
  cat("Building incidence matrix...\n")
  incidence_raw <- build_layer_incidence(adj_prod_fg, adj_util_fg, layer)
  filtered_result <- remove_zero_degree(incidence_raw, layer)
  incidence <- filtered_result$incidence
  removal_summary <- filtered_result$removal_summary

  if (sum(incidence) == 0) {
    cat("Warning: No interactions in filtered matrix. Skipping layer.\n")
    all_results[[layer]] <- list(
      layer = layer,
      status = "failed",
      reason = "no_interactions",
      removal_summary = removal_summary
    )
    next
  }

  cat(sprintf(
    "Matrix: %d × %d (%d interactions, %.1f%% fill)\n",
    nrow(incidence), ncol(incidence),
    sum(incidence), 100 * sum(incidence) / (nrow(incidence) * ncol(incidence))
  ))

  # 2. Get observed modularity (single run)
  cat("Computing observed modularity...\n")
  obs_result <- compute_modularity_safe(incidence, seed = master_seed)
  obs_Q <- extract_Q_value(obs_result)

  if (is.na(obs_Q)) {
    cat("Warning: Could not compute observed modularity. Skipping layer.\n")
    all_results[[layer]] <- list(
      layer = layer,
      status = "failed",
      reason = "obs_Q_failed",
      removal_summary = removal_summary
    )
    next
  }

  cat(sprintf("Observed Q: %.4f\n", obs_Q))

  # 3. Compute observed stability metrics
  obs_stability <- compute_observed_stability(incidence, master_seed, layer)
  cat(sprintf(
    "Observed stability: mean_Q=%.4f, sd=%.4f, CV=%.4f, mean_ARI=%.4f (IQR: %.4f-%.4f) (%d valid)",
    obs_stability$mean_Q, obs_stability$sd_Q, obs_stability$CV,
    obs_stability$mean_ARI, obs_stability$ari_iqr_lower, obs_stability$ari_iqr_upper,
    obs_stability$n_valid
  ))

  # 4. Generate null models
  cat(sprintf("Generating %d degree-preserving nulls...\n", n_nulls))

  null_Q_values <- numeric(n_nulls)
  valid_nulls <- 0

  # Store successful null matrices for stability analysis (efficient approach)
  successful_null_matrices <- list()
  successful_null_indices <- numeric(0)

  # Generate unique seeds for each null
  null_seeds <- master_seed + seq_len(n_nulls) * 10000

  for (i in 1:n_nulls) {
    cat(sprintf("  Null %d/%d (seed=%d)...\n", i, n_nulls, null_seeds[i]))

    # Generate a single null matrix using bipartite swap.web
    # Compute adaptive swaps based on number of edges
    edge_count <- sum(incidence)
    times_swap <- max(100, 10 * edge_count) # Minimum 100 swaps, or 10×edge count

    null_matrix <- tryCatch(
      {
        vegan::swap.web(incidence, method = "quasiswap", times = times_swap)
      },
      error = function(e) {
        message("swap.web failed with error: ", e$message)
        NULL
      }
    )

    if (!is.null(null_matrix)) {
      # Validate exact degree preservation with proper numerical tolerance
      row_sums_orig <- rowSums(incidence)
      row_sums_null <- rowSums(null_matrix)
      col_sums_orig <- colSums(incidence)
      col_sums_null <- colSums(null_matrix)

      # Use numerical tolerance instead of all.equal() boolean logic
      tolerance <- 1e-10
      row_sums_preserved <- all(abs(row_sums_orig - row_sums_null) < tolerance)
      col_sums_preserved <- all(abs(col_sums_orig - col_sums_null) < tolerance)

      # Validate that null matrix is actually different from original
      matrix_different <- !identical(incidence, null_matrix)
      if (!matrix_different) {
        cat(sprintf("WARNING: Null matrix identical to original for null %d (insufficient shuffling)\n", i))
      }

      # Only proceed if degree preserved AND matrix is actually shuffled
      if (!(row_sums_preserved && col_sums_preserved)) {
        row_diff <- max(abs(row_sums_orig - row_sums_null))
        col_diff <- max(abs(col_sums_orig - col_sums_null))
        cat(sprintf(
          "WARNING: Degree preservation failed for null %d (max row diff: %.2e, max col diff: %.2e)\n",
          i, row_diff, col_diff
        ))
        null_Q_values[i] <- NA_real_
        cat(sprintf("  Info: Skipping modularity for invalid null %d\n", i))
        next
      }

      if (!matrix_different) {
        null_Q_values[i] <- NA_real_
        cat(sprintf("  Info: Skipping modularity for unshuffled null %d\n", i))
        next
      }

      # Compute modularity on the null matrix with same deterministic approach
      null_mod_result <- compute_modularity_safe(null_matrix, seed = null_seeds[i])
      null_Q <- extract_Q_value(null_mod_result)

      if (!is.na(null_Q)) {
        null_Q_values[i] <- null_Q
        valid_nulls <- valid_nulls + 1

        # Store successful null matrix for stability analysis (no regeneration needed!)
        successful_null_matrices[[length(successful_null_matrices) + 1]] <- null_matrix
        successful_null_indices <- c(successful_null_indices, i)
      } else {
        null_Q_values[i] <- NA_real_
        cat(sprintf("  Warning: Modularity computation failed for null %d\n", i))
      }
    } else {
      null_Q_values[i] <- NA_real_
      cat(sprintf("  Warning: Null generation failed for null %d\n", i))
    }
  }

  # Remove NA values for analysis
  null_Q_clean <- null_Q_values[!is.na(null_Q_values)]

  if (length(null_Q_clean) < 5) {
    cat("Warning: Too few valid null Q values. Skipping layer.\n")
    all_results[[layer]] <- list(
      layer = layer,
      status = "failed",
      reason = "insufficient_nulls",
      removal_summary = removal_summary,
      obs_Q = obs_Q,
      valid_nulls = 0
    )
    next
  }

  # 5a. Assess null distribution stability on sample of null matrices (memory-efficient)
  cat("Assessing null distribution stability...\n")
  null_stability_samples <- min(10, length(successful_null_matrices)) # Sample 10 null matrices for stability
  null_stability_results <- list()

  # Use stored null matrices instead of regenerating (2x faster!)
  for (sample_idx in 1:null_stability_samples) {
    null_matrix <- successful_null_matrices[[sample_idx]]
    original_null_idx <- successful_null_indices[sample_idx]

    if (!is.null(null_matrix)) {
      cat(sprintf(
        "  Stability analysis for null matrix %d (original index: %d)...\n",
        sample_idx, original_null_idx
      ))

      # Compute stability metrics for this stored null matrix
      stability <- compute_null_stability(null_matrix, n_stability_reps = 3, master_seed + original_null_idx * 1000)
      null_stability_results[[sample_idx]] <- stability
    }
  }

  # Memory cleanup - free up space from stored matrices
  rm(successful_null_matrices)
  gc() # Force garbage collection

  # Aggregate null stability metrics
  valid_null_stabilities <- null_stability_results[!sapply(null_stability_results, function(x) is.null(x$n_valid) && x$n_valid == 0)]
  if (length(valid_null_stabilities) > 0) {
    null_cv_mean <- mean(sapply(valid_null_stabilities, function(x) ifelse(is.na(x$CV), 0, x$CV)), na.rm = TRUE)
    null_ari_mean <- mean(sapply(valid_null_stabilities, function(x) ifelse(is.na(x$mean_ARI), 0, x$mean_ARI)), na.rm = TRUE)
  } else {
    null_cv_mean <- NA_real_
    null_ari_mean <- NA_real_
  }

  # 5. Compute null statistics
  # Null summary statistics
  null_mean <- mean(null_Q_clean)
  null_sd <- sd(null_Q_clean)
  null_min <- min(null_Q_clean)
  null_max <- max(null_Q_clean)

  # Compute p-value (two-tailed for comprehensive significance testing)
  # More robust approach for biological network analysis
  null_ge_obs <- sum(null_Q_clean >= obs_Q)
  null_le_obs <- sum(null_Q_clean <= obs_Q)

  # Two-tailed p-value with +1 correction
  p_value_twotailed <- 2 * min(
    (null_ge_obs + 1) / (length(null_Q_clean) + 1),
    (null_le_obs + 1) / (length(null_Q_clean) + 1)
  )

  # Also report one-tailed p-value for completeness
  p_value_onetail_higher <- (null_ge_obs + 1) / (length(null_Q_clean) + 1) # Higher than expected
  p_value_onetail_lower <- (null_le_obs + 1) / (length(null_Q_clean) + 1) # Lower than expected

  # Compute SES
  ses <- (obs_Q - null_mean) / null_sd

  # Independence check (split nulls in half)
  independence_check <- "insufficient_nulls"
  if (length(null_Q_clean) >= 20) {
    n_half <- length(null_Q_clean) %/% 2
    first_half <- null_Q_clean[1:n_half]
    second_half <- null_Q_clean[(n_half + 1):length(null_Q_clean)]
    mean_diff <- abs(mean(first_half) - mean(second_half))
    if (mean_diff < 0.01) {
      independence_check <- "passed"
    } else {
      independence_check <- sprintf("warning (diff=%.3f)", mean_diff)
    }
  }

  cat(sprintf(
    "Null results: mean=%.4f±%.4f, range=%.4f-%.4f, p_twotailed=%.4f, p_onetail(higher)=%.4f, SES=%.2f\n",
    null_mean, null_sd, null_min, null_max, p_value_twotailed, p_value_onetail_higher, ses
  ))
  cat(sprintf("Null independence: %s (%d valid nulls)\n", independence_check, length(null_Q_clean)))
  if (!is.na(null_cv_mean)) {
    cat(sprintf("Null stability: CV=%.3f, mean_ARI=%.3f\n", null_cv_mean, null_ari_mean))
  }

  # 6. Store results
  layer_end_time <- Sys.time()
  layer_elapsed <- as.numeric(difftime(layer_end_time, layer_start_time, units = "secs"))

  all_results[[layer]] <- list(
    layer = layer,
    status = "success",
    removal_summary = removal_summary,
    incidence_dims = dim(incidence),
    incidence_fill = sum(incidence) / (nrow(incidence) * ncol(incidence)),
    obs_Q = obs_Q,
    obs_stability = obs_stability,
    null_mean = null_mean,
    null_sd = null_sd,
    null_min = null_min,
    null_max = null_max,
    p_value_twotailed = p_value_twotailed,
    p_value_onetail_higher = p_value_onetail_higher,
    p_value_onetail_lower = p_value_onetail_lower,
    ses = ses,
    valid_nulls = length(null_Q_clean),
    independence_check = independence_check,
    null_stability_cv = null_cv_mean,
    null_stability_ari = null_ari_mean,
    n_nulls_requested = n_nulls,
    elapsed_sec = layer_elapsed
  )

  cat(sprintf("Layer %s completed in %.2f seconds\n", layer, layer_elapsed))
}

# -----------------------------
# Generate consolidated summary
# -----------------------------
cat("\nGenerating consolidated summary...\n")

summary_lines <- c(
  "Phase 04 - Step 03c: Layer-Specific Null Model Modularity Test Summary",
  paste("Timestamp:", timestamp()),
  paste("Master seed:", master_seed),
  paste("Nulls per layer:", n_nulls),
  "",
  "Method:",
  "  Null generation: vegan::swap.web(method = 'quasiswap')",
  "  Modularity: bipartite::computeModules (Beckett method - same as main function)",
  "  Statistical testing: two-tailed empirical with +1 correction",
  "  Stability assessment: CV and ARI metrics for both observed and null distributions",
  "  SES: (observed - null_mean) / null_sd",
  ""
)

# Add layer-specific results
for (layer in names(all_results)) {
  result <- all_results[[layer]]

  summary_lines <- c(
    summary_lines,
    paste(stringr::str_to_title(layer), "Layer:"),
    paste("  Status:", result$status)
  )

  if (result$status == "success") {
    summary_lines <- c(
      summary_lines,
      sprintf(
        "  Matrix: %d × %d (%.1f%% fill)",
        result$incidence_dims[1], result$incidence_dims[2],
        100 * result$incidence_fill
      ),
      sprintf(
        "  Nodes removed: %d FGs, %d PYOVs",
        result$removal_summary$zero_rows_removed,
        result$removal_summary$zero_cols_removed
      ),
      sprintf("  Observed Q: %.4f", result$obs_Q),
      sprintf(
        "  Observed stability: mean=%.4f, sd=%.4f, CV=%.4f, mean_ARI=%.4f (%d valid)",
        result$obs_stability$mean_Q, result$obs_stability$sd_Q,
        result$obs_stability$CV, result$obs_stability$mean_ARI,
        result$obs_stability$n_valid
      ),
      sprintf(
        "  Null distribution: mean=%.4f±%.4f, range=%.4f-%.4f",
        result$null_mean, result$null_sd, result$null_min, result$null_max
      ),
      sprintf(
        "  Statistical test: p_twotailed=%.4f, p_onetail(higher)=%.4f, SES=%.2f",
        result$p_value_twotailed, result$p_value_onetail_higher, result$ses
      ),
      sprintf(
        "  Significance: %s",
        ifelse(result$p_value_twotailed < 0.05, "SIGNIFICANT", "Not significant")
      ),
      sprintf(
        "  Independence: %s (%d valid nulls)",
        result$independence_check, result$valid_nulls
      ),
      sprintf(
        "  Null stability: CV=%.3f, ARI=%.3f",
        ifelse(is.na(result$null_stability_cv), "NA", result$null_stability_cv),
        ifelse(is.na(result$null_stability_ari), "NA", result$null_stability_ari)
      ),
      sprintf("  Runtime: %.2f seconds", result$elapsed_sec)
    )

    # Interpretation guidance
    if (result$ses > 2) {
      summary_lines <- c(summary_lines, "  Interpretation: Strong positive deviation (more modular than expected)")
    } else if (result$ses < -2) {
      summary_lines <- c(summary_lines, "  Interpretation: Strong negative deviation (less modular than expected)")
    } else {
      summary_lines <- c(summary_lines, "  Interpretation: Within expected range given degree constraints")
    }
  } else {
    summary_lines <- c(
      summary_lines,
      paste("  Reason:", result$reason)
    )
  }

  summary_lines <- c(summary_lines, "")
}

# Add general interpretation notes
summary_lines <- c(
  summary_lines,
  "Interpretation Guidelines:",
  "  SES > 2: Strong positive deviation (more modular than expected)",
  "  SES < -2: Strong negative deviation (less modular than expected)",
  "  |SES| < 2: Within expected range given degree constraints",
  "  p_twotailed < 0.05: Statistically significant deviation",
  "  Null CV > 0.10: High variability in null modularity estimates",
  "  Null mean ARI < 0.60: Low consistency in null partitions",
  "",
  "Notes:",
  "  - Null models preserve layer-specific degree sequences using bipartite swaps",
  "  - Quasi-swap method ensures degree preservation for bipartite networks",
  "  - Algorithm parameters EXACTLY match main function for valid comparison",
  "  - Stability assessed on samples of null matrices using replicates",
  "  - Two-tailed testing more appropriate for comprehensive biological analysis",
  "  - Results are for FG-level networks only",
  "",
  "Output saved to: scripts/phase_04_topology/debug/logs/03c_null_modularity_summary.txt"
)

# Write summary
summary_file <- "scripts/phase_04_topology/debug/logs/03c_null_modularity_summary.txt"
writeLines(summary_lines, summary_file)

# Save session info
session_file <- "scripts/phase_04_topology/debug/logs/03c_null_session_info.txt"
writeLines(capture.output(sessionInfo()), session_file)

# Display summary
cat("\n", paste(summary_lines, collapse = "\n"), "\n")

cat("\n=== Null Model Modularity Test Complete ===\n")
cat(sprintf("Summary saved to: %s\n", summary_file))
cat(sprintf("Session info saved to: %s\n", session_file))
cat("Note: Compact mode - only text summaries saved (no RDS/figures)\n")
