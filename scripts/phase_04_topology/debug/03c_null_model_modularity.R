#!/usr/bin/env Rscript

# Phase 04 - Step 03c: Layer-Specific Null Model Modularity Test (Debug/Logs-Only)
# ------------------------------------------------------------------------------
# Purpose:
#   Test statistical significance of observed modularity for production and
#   utilization layers using degree-preserving bipartite null models.
#
# Method:
#   - Accept layer argument (production or utilization) or run both serially
#   - Generate N degree-preserving nulls (default N=100) for the given layer
#   - For each null, compute modularity Q via computeModules() (single run)
#   - Report null summary statistics, p-value (+1 correction), SES
#   - Include small observed stability check (R=20)
#   - Save only text summary (no RDS/figures) in debug logs
#
# Usage:
#   Rscript scripts/phase_04_topology/debug/03c_null_model_modularity.R --layer production
#   Rscript scripts/phase_04_topology/debug/03c_null_model_modularity.R --layer utilization
#   Rscript scripts/phase_04_topology/debug/03c_null_model_modularity.R  # runs both
#
# Author: automated assistant
# Date: autogenerated

suppressPackageStartupMessages({
  library(Matrix)
  library(ggplot2)
  library(dplyr)
  library(bipartite)
  library(vegan)
  library(jsonlite)
  library(stringr)
})

# -----------------------------
# Helper functions
# -----------------------------
safe_dir_create <- function(path) {
  if (!dir.exists(path)) dir.create(path, recursive = TRUE, showWarnings = FALSE)
}

timestamp <- function() format(Sys.time(), "%Y-%m-%d %H:%M:%S %Z")

# Build layer-specific incidence matrix
build_layer_incidence <- function(adj_production, adj_utilization, layer = "production") {
  if (layer == "production") {
    incidence <- as.matrix(adj_production > 0) * 1
  } else if (layer == "utilization") {
    incidence <- as.matrix(t(adj_utilization) > 0) * 1
  } else {
    stop("Layer must be 'production' or 'utilization'")
  }
  return(incidence)
}

# Remove zero-degree rows and columns
remove_zero_degree <- function(incidence, layer_name) {
  initial_dims <- dim(incidence)

  row_degrees <- rowSums(incidence)
  col_degrees <- colSums(incidence)

  zero_rows <- which(row_degrees == 0)
  zero_cols <- which(col_degrees == 0)

  if (length(zero_rows) > 0) {
    incidence <- incidence[-zero_rows, , drop = FALSE]
  }
  if (length(zero_cols) > 0) {
    incidence <- incidence[, -zero_cols, drop = FALSE]
  }

  final_dims <- dim(incidence)

  removal_summary <- list(
    layer = layer_name,
    initial_dims = initial_dims,
    final_dims = final_dims,
    zero_rows_removed = length(zero_rows),
    zero_cols_removed = length(zero_cols)
  )

  return(list(incidence = incidence, removal_summary = removal_summary))
}

# Compute modularity with error handling
compute_modularity_safe <- function(incidence, seed = NULL) {
  if (!is.null(seed)) set.seed(seed)

  result <- tryCatch(
    {
      bipartite::computeModules(incidence,
        method = "Beckett",
        deep = FALSE,
        deleteOriginalFiles = TRUE,
        steps = 1000000,
        tolerance = 1e-10,
        experimental = FALSE,
        forceLPA = FALSE
      )
    },
    error = function(e) {
      message("computeModules failed with error: ", e$message)
      NULL
    }
  )

  return(result)
}

# Extract Q value from bipartite result
extract_Q_value <- function(module_result) {
  if (is.null(module_result)) {
    return(NA_real_)
  }

  Q <- module_result@likelihood
  return(Q)
}

# Compute ARI between partitions
compute_partition_ari <- function(partition1, partition2) {
  if (length(partition1) != length(partition2)) {
    return(NA_real_)
  }
  return(as.numeric(mclust::adjustedRandIndex(partition1, partition2)))
}

# Enhanced observed stability function with ARI computation
compute_observed_stability <- function(incidence, master_seed, layer) {
  cat("Computing observed stability metrics (R=20)...\n")

  R_stability <- 20
  Q_values <- numeric(R_stability)
  partition_list <- list()

  for (rep in 1:R_stability) {
    rep_seed <- master_seed + rep * 1000

    # Compute modularity and store both Q and partition
    module_result <- compute_modularity_safe(incidence, seed = rep_seed)
    Q_values[rep] <- extract_Q_value(module_result)

    # Store partition if modules found
    if (!is.null(module_result$modules)) {
      partition_list[[rep]] <- module_result$modules$module_id
    } else {
      partition_list[[rep]] <- NULL
    }
  }

  # Compute Q statistics
  valid_Q <- Q_values[!is.na(Q_values)]
  if (length(valid_Q) == 0) {
    return(list(
      n_valid = 0,
      mean_Q = NA_real_,
      sd_Q = NA_real_,
      CV = NA_real_,
      mean_ARI = NA_real_,
      ari_iqr_lower = NA_real_,
      ari_iqr_upper = NA_real_
    ))
  }

  # Compute ARI between all pairs of partitions
  ari_values <- numeric(0)
  valid_partitions <- which(!sapply(partition_list, is.null))

  if (length(valid_partitions) >= 2) {
    for (i in 1:(length(valid_partitions) - 1)) {
      for (j in (i + 1):length(valid_partitions)) {
        ari <- compute_partition_ari(
          partition_list[[valid_partitions[i]]],
          partition_list[[valid_partitions[j]]]
        )
        if (!is.na(ari)) {
          ari_values <- c(ari_values, ari)
        }
      }
    }
  }

  mean_ari <- if (length(ari_values) > 0) mean(ari_values, na.rm = TRUE) else NA_real_
  ari_iqr <- if (length(ari_values) > 0) {
    quantile(ari_values, probs = c(0.25, 0.75), na.rm = TRUE)
  } else {
    c(NA_real_, NA_real_)
  }

  return(list(
    n_valid = length(valid_Q),
    mean_Q = mean(valid_Q),
    sd_Q = sd(valid_Q),
    CV = ifelse(mean(valid_Q) > 0, sd(valid_Q) / mean(valid_Q), NA_real_),
    mean_ARI = mean_ari,
    ari_iqr_lower = ari_iqr[1],
    ari_iqr_upper = ari_iqr[2]
  ))
}



# -----------------------------
# Command line argument parsing
# -----------------------------
args <- commandArgs(trailingOnly = TRUE)
if (length(args) == 0) {
  run_both <- TRUE
  target_layer <- NULL
} else if (length(args) == 1 && args[1] %in% c("production", "utilization")) {
  run_both <- FALSE
  target_layer <- args[1]
} else {
  stop("Usage: Rscript 03c_null_model_modularity.R [--layer production|utilization]")
}

layers_to_run <- if (run_both) c("production", "utilization") else target_layer

# -----------------------------
# Directory setup
# -----------------------------
safe_dir_create("scripts/phase_04_topology/debug/logs")

cat("=== Phase 04 - Step 03c: Layer-Specific Null Model Modularity Test ===\n")
cat(paste("Timestamp:", timestamp(), "\n"))
cat(sprintf("Layers to test: %s\n", paste(layers_to_run, collapse = ", ")))

# -----------------------------
# Load parameters from manifest
# -----------------------------
manifest_json <- "docs/phase_04/parameters_manifest.json"
manifest <- list()
if (file.exists(manifest_json)) {
  manifest <- tryCatch(fromJSON(manifest_json), error = function(e) {
    message("Could not parse manifest JSON; using defaults")
    list()
  })
}

master_seed <- if (!is.null(manifest$master_seed)) manifest$master_seed else 2025
n_nulls_pilot <- if (!is.null(manifest$null_model_N[["pilot"]])) manifest$null_model_N[["pilot"]] else 100

cat(sprintf("Parameters: master_seed=%d, n_nulls=%d\n", master_seed, n_nulls_pilot))

# -----------------------------
# Load and validate inputs
# -----------------------------
cat("Loading adjacency matrices...\n")

required_files <- list(
  adj_prod_fg = "data/interim/adj_production_FG_agentsxpyov_conservative.rds",
  adj_util_fg = "data/interim/adj_utilization_FG_pyovxagents_conservative.rds"
)

for (name in names(required_files)) {
  if (!file.exists(required_files[[name]])) {
    stop("Required input missing: ", required_files[[name]])
  }
}

adj_prod_fg <- readRDS(required_files$adj_prod_fg)
adj_util_fg <- readRDS(required_files$adj_util_fg)

# -----------------------------
# Process each layer
# -----------------------------
all_results <- list()

for (layer in layers_to_run) {
  cat(sprintf("\n=== Testing %s layer ===\n", stringr::str_to_title(layer)))

  layer_start_time <- Sys.time()

  # 1. Build and filter incidence matrix
  cat("Building incidence matrix...\n")
  incidence_raw <- build_layer_incidence(adj_prod_fg, adj_util_fg, layer)
  filtered_result <- remove_zero_degree(incidence_raw, layer)
  incidence <- filtered_result$incidence
  removal_summary <- filtered_result$removal_summary

  if (sum(incidence) == 0) {
    cat("Warning: No interactions in filtered matrix. Skipping layer.\n")
    all_results[[layer]] <- list(
      layer = layer,
      status = "failed",
      reason = "no_interactions",
      removal_summary = removal_summary
    )
    next
  }

  cat(sprintf(
    "Matrix: %d × %d (%d interactions, %.1f%% fill)\n",
    nrow(incidence), ncol(incidence),
    sum(incidence), 100 * sum(incidence) / (nrow(incidence) * ncol(incidence))
  ))

  # 2. Get observed modularity (single run)
  cat("Computing observed modularity...\n")
  obs_result <- compute_modularity_safe(incidence, seed = master_seed)
  obs_Q <- extract_Q_value(obs_result)

  if (is.na(obs_Q)) {
    cat("Warning: Could not compute observed modularity. Skipping layer.\n")
    all_results[[layer]] <- list(
      layer = layer,
      status = "failed",
      reason = "obs_Q_failed",
      removal_summary = removal_summary
    )
    next
  }

  cat(sprintf("Observed Q: %.4f\n", obs_Q))

  # 3. Compute observed stability metrics
  obs_stability <- compute_observed_stability(incidence, master_seed, layer)
  cat(sprintf(
    "Observed stability: mean_Q=%.4f, sd=%.4f, CV=%.4f (%d valid)\n",
    obs_stability$mean_Q, obs_stability$sd_Q, obs_stability$CV, obs_stability$n_valid
  ))

  # 4. Generate null models
  cat(sprintf("Generating %d degree-preserving nulls...\n", n_nulls_pilot))

  null_Q_values <- numeric(n_nulls_pilot)
  valid_nulls <- 0

  # Generate unique seeds for each null
  null_seeds <- master_seed + seq_len(n_nulls_pilot) * 10000

  for (i in 1:n_nulls_pilot) {
    if (i %% 20 == 0 || i <= 5) {
      cat(sprintf("  Null %d/%d (seed=%d)...\n", i, n_nulls_pilot, null_seeds[i]))
    }

    # Generate a single null matrix using bipartite swap.web
    # Compute adaptive swaps based on number of edges
    edge_count <- sum(incidence)
    times_swap <- max(100, 10 * edge_count)  # Minimum 100 swaps, or 10×edge count as specified in method

    null_matrix <- tryCatch(
      {
        vegan::swap.web(incidence, method = "quasiswap", times = times_swap)
      },
      error = function(e) {
        message("swap.web failed with error: ", e$message)
        NULL
      }
      sprintf("  Observed stability: mean_Q=%.4f, sd=%.4f, CV=%.4f, mean_ARI=%.4f (IQR: %.4f-%.4f) (%d valid)",

    # Compute adaptive swaps based on number of edges
    edge_count <- sum(incidence)
    times_swap <- max(100, 10 * edge_count)  # Minimum 100 swaps, or 10×edge count

    # Generate a single null matrix using bipartite swap.web
    null_matrix <- tryCatch(
      # Validate exact degree preservation with no tolerance (as required by method)
      row_sums_preserved <- isTRUE(all.equal(rowSums(incidence), rowSums(null_matrix), check.names = FALSE))
      col_sums_preserved <- isTRUE(all.equal(colSums(incidence), colSums(null_matrix), check.names = FALSE))
      if (!(row_sums_preserved && col_sums_preserved)) {
        cat(sprintf("WARNING: Degree preservation failed for null %d (row sums preserved: %s, col sums preserved: %s)\n",
                    i, row_sums_preserved, col_sums_preserved))
      }

      # Compute modularity on the null matrix
      null_mod_result <- compute_modularity_safe(null_matrix, seed = NULL)
      null_Q <- extract_Q_value(null_mod_result)

      if (!is.na(null_Q)) {
        null_Q_values[i] <- null_Q
        valid_nulls <- valid_nulls + 1
      } else {
        null_Q_values[i] <- NA_real_
        cat(sprintf("  Warning: Modularity computation failed for null %d\n", i))
      }
    } else {
      null_Q_values[i] <- NA_real_
      cat(sprintf("  Warning: Null generation failed for null %d\n", i))
    }


  # Remove NA values for analysis
  null_Q_clean <- null_Q_values[!is.na(null_Q_values)]

  if (length(null_Q_clean) < 5) {
    cat("Warning: Too few valid null Q values. Skipping layer.\n")
    all_results[[layer]] <- list(
      layer = layer,
      status = "failed",
      reason = "insufficient_nulls",
      removal_summary = removal_summary,
      obs_Q = obs_Q,
      valid_nulls = 0
    )
    next
  }

  # 5. Compute null statistics
  # Null summary statistics
  null_mean <- mean(null_Q_clean)
  null_sd <- sd(null_Q_clean)
  null_min <- min(null_Q_clean)
  null_max <- max(null_Q_clean)

  # Compute p-value (one-tailed: probability null >= observed)
  # Testing for higher modularity than expected by chance (consistent with method document)
  p_value <- (sum(null_Q_clean >= obs_Q) + 1) / (length(null_Q_clean) + 1)

  # Compute SES
  ses <- (obs_Q - null_mean) / null_sd

  # Independence check (split nulls in half)
  independence_check <- "insufficient_nulls"
  if (length(null_Q_clean) >= 20) {
    n_half <- length(null_Q_clean) %/% 2
    first_half <- null_Q_clean[1:n_half]
    second_half <- null_Q_clean[(n_half + 1):length(null_Q_clean)]
    mean_diff <- abs(mean(first_half) - mean(second_half))
    if (mean_diff < 0.01) {
      independence_check <- "passed"
    } else {
      independence_check <- sprintf("warning (diff=%.3f)", mean_diff)
    }
  }

  cat(sprintf(
    "Null results: mean=%.4f±%.4f, range=%.4f-%.4f, p=%.4f, SES=%.2f\n",
    null_mean, null_sd, null_min, null_max, p_value, ses
  ))
  cat(sprintf("Null independence: %s (%d valid nulls)\n", independence_check, length(null_Q_clean)))

  # 6. Store results
  layer_end_time <- Sys.time()
  layer_elapsed <- as.numeric(difftime(layer_end_time, layer_start_time, units = "secs"))

  all_results[[layer]] <- list(
    layer = layer,
    status = "success",
    removal_summary = removal_summary,
    incidence_dims = dim(incidence),
    incidence_fill = sum(incidence) / (nrow(incidence) * ncol(incidence)),
    obs_Q = obs_Q,
    obs_stability = obs_stability,
    null_mean = null_mean,
    null_sd = null_sd,
    null_min = null_min,
    null_max = null_max,
    p_value = p_value,
    ses = ses,
    valid_nulls = length(null_Q_clean),
    independence_check = independence_check,
    n_nulls_requested = n_nulls_pilot,
    elapsed_sec = layer_elapsed
  )

  cat(sprintf("Layer %s completed in %.2f seconds\n", layer, layer_elapsed))
}

# -----------------------------
# Generate consolidated summary
# -----------------------------
cat("\nGenerating consolidated summary...\n")

summary_lines <- c(
  "Phase 04 - Step 03c: Layer-Specific Null Model Modularity Test Summary",
  paste("Timestamp:", timestamp()),
  paste("Master seed:", master_seed),
  paste("Nulls per layer:", n_nulls_pilot),
  "",
  "Method:",
  "  Null generation: vegan::swap.web(method = 'quasiswap')",
  "  Modularity: bipartite::computeModules (Beckett method)",
  "  P-value: one-tailed empirical (+1 correction, testing for higher modularity)",
  "  SES: (observed - null_mean) / null_sd",
  ""
)

# Add layer-specific results
for (layer in names(all_results)) {
  result <- all_results[[layer]]

  summary_lines <- c(
    summary_lines,
    paste(stringr::str_to_title(layer), "Layer:"),
    paste("  Status:", result$status)
  )

  if (result$status == "success") {
    summary_lines <- c(
      summary_lines,
      sprintf(
        "  Matrix: %d × %d (%.1f%% fill)",
        result$incidence_dims[1], result$incidence_dims[2],
        100 * result$incidence_fill
      ),
      sprintf(
        "  Nodes removed: %d FGs, %d PYOVs",
        result$removal_summary$zero_rows_removed,
        result$removal_summary$zero_cols_removed
      ),
      sprintf("  Observed Q: %.4f", result$obs_Q),
      sprintf(
        "  Observed stability: mean=%.4f, sd=%.4f, CV=%.4f (%d valid)",
        result$obs_stability$mean_Q, result$obs_stability$sd_Q,
        result$obs_stability$CV, result$obs_stability$n_valid
      ),
      sprintf(
        "  Null distribution: mean=%.4f±%.4f, range=%.4f-%.4f",
        result$null_mean, result$null_sd, result$null_min, result$null_max
      ),
      sprintf("  Statistical test: p=%.4f, SES=%.2f (one-tailed for higher modularity)", result$p_value, result$ses),
      sprintf(
        "  Significance: %s",
        ifelse(result$p_value < 0.05, "SIGNIFICANT", "Not significant")
      ),
      sprintf(
        "  Independence: %s (%d valid nulls)",
        result$independence_check, result$valid_nulls
      ),
      sprintf("  Runtime: %.2f seconds", result$elapsed_sec)
    )

    # Interpretation guidance
    if (result$ses > 2) {
      summary_lines <- c(summary_lines, "  Interpretation: Strong positive deviation (more modular than expected)")
    } else if (result$ses < -2) {
      summary_lines <- c(summary_lines, "  Interpretation: Strong negative deviation (less modular than expected)")
    } else {
      summary_lines <- c(summary_lines, "  Interpretation: Within expected range given degree constraints")
    }
  } else {
    summary_lines <- c(
      summary_lines,
      paste("  Reason:", result$reason)
    ),
    sprintf("  Observed stability: mean_Q=%.4f, sd=%.4f, CV=%.4f, mean_ARI=%.4f (IQR: %.4f-%.4f) (%d valid)",

  summary_lines <- c(summary_lines, "")
}

# Add general interpretation notes
summary_lines <- c(
  summary_lines,
  "Interpretation Guidelines:",
  "  SES > 2: Strong positive deviation (more modular than expected)",
  "  SES < -2: Strong negative deviation (less modular than expected)",
  "  |SES| < 2: Within expected range given degree constraints",
  "  p < 0.05: Statistically significant deviation",
  "",
  "Notes:",
  "  - Null models preserve layer-specific degree sequences using bipartite swaps",
  "  - Quasi-swap method ensures degree preservation for bipartite networks",
  "  - Each null performs 1000 swaps for adequate mixing",
  "  - Results are for FG-level networks only",
  "  - For STR-level analysis, adjust runtime expectations",
  "",
  "Output saved to: scripts/phase_04_topology/debug/logs/03c_null_modularity_summary.txt"
)

# Write summary
summary_file <- "scripts/phase_04_topology/debug/logs/03c_null_modularity_summary.txt"
writeLines(summary_lines, summary_file)

# Save session info
session_file <- "scripts/phase_04_topology/debug/logs/03c_null_session_info.txt"
writeLines(capture.output(sessionInfo()), session_file)

# Display summary
cat("\n", paste(summary_lines, collapse = "\n"), "\n")

cat("\n=== Null Model Modularity Test Complete ===\n")
cat(sprintf("Summary saved to: %s\n", summary_file))
cat(sprintf("Session info saved to: %s\n", session_file))
cat("Note: Compact mode - only text summaries saved (no RDS/figures)\n")
