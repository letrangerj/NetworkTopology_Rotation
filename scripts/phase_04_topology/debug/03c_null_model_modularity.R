#!/usr/bin/env Rscript

# Phase 04 - Step 03c: Layer-Specific Null Model Modularity Test (Debug/Logs-Only)
# ------------------------------------------------------------------------------
# Purpose:
#   Test statistical significance of observed modularity for production and
#   utilization layers using degree-preserving bipartite null models.
#
# Method:
#   - Accept layer argument (production or utilization) or run both serially
#   - Generate N degree-preserving nulls based on manifest parameters
#   - For each null, compute modularity Q via computeModules() (single run)
#   - Report null summary statistics, two-tailed p-value (+1 correction), SES
#   - Include comprehensive stability assessment (R=20 for observed, sample for nulls)
#   - Save only text summary (no RDS/figures) in debug logs
#
# Usage:
#   Rscript scripts/phase_04_topology/debug/03c_null_model_modularity.R --layer production
#   Rscript scripts/phase_04_topology/debug/03c_null_model_modularity.R --layer utilization
#   Rscript scripts/phase_04_topology/debug/03c_null_model_modularity.R  # runs both layers
#   Rscript scripts/phase_04_topology/debug/03c_null_model_modularity.R --pilot  # use pilot null count
#   Rscript scripts/phase_04_topology/debug/03c_null_model_modularity.R --final  # use final null count
#
# Author: automated assistant
# Date: autogenerated

suppressPackageStartupMessages({
  library(Matrix)
  library(ggplot2)
  library(dplyr)
  library(bipartite)
  library(vegan)
  library(jsonlite)
  library(stringr)
  library(mclust)
})

# -----------------------------
# Helper functions
# -----------------------------
safe_dir_create <- function(path) {
  if (!dir.exists(path)) dir.create(path, recursive = TRUE, showWarnings = FALSE)
}

timestamp <- function() format(Sys.time(), "%Y-%m-%d %H:%M:%S %Z")

# Robust extraction for simulated null matrices from vegan::nullmodel + simulate
extract_sim_mats <- function(sim_obj) {
  # Handles list of matrices or 3D arrays
  if (is.null(sim_obj)) return(list())
  if (is.list(sim_obj)) {
    return(lapply(sim_obj, function(m) as.matrix(m)))
  }
  if (length(dim(sim_obj)) == 3) {
    k <- dim(sim_obj)[3]
    out <- vector("list", k)
    for (i in seq_len(k)) out[[i]] <- as.matrix(sim_obj[,,i])
    return(out)
  }
  if (is.matrix(sim_obj)) return(list(as.matrix(sim_obj)))
  list()
}

# Generate curveball nulls efficiently in batches
generate_curveball_nulls <- function(incidence, n_nulls, seed) {
  set.seed(seed)
  nm <- vegan::nullmodel(incidence, method = "curveball")
  sim <- tryCatch(vegan::simulate(nm, nsim = n_nulls), error = function(e) NULL)
  if (!is.null(sim)) return(extract_sim_mats(sim))
  # Fallback: one-by-one
  mats <- vector("list", n_nulls)
  for (i in seq_len(n_nulls)) {
    set.seed(seed + i)
    mats[[i]] <- tryCatch(as.matrix(vegan::simulate(nm)), error = function(e) NULL)
  }
  mats
}

# Build layer-specific incidence matrix
build_layer_incidence <- function(adj_production, adj_utilization, layer = "production") {
  if (layer == "production") {
    incidence <- as.matrix(adj_production > 0) * 1
  } else if (layer == "utilization") {
    incidence <- as.matrix(t(adj_utilization) > 0) * 1
    if (!all(rownames(incidence) == rownames(adj_production))) {
      stop("Row name mismatch between production and utilization layers")
    }
  } else {
    stop("Layer must be 'production' or 'utilization'")
  }
  return(incidence)
}

# Remove zero-degree rows and columns
remove_zero_degree <- function(incidence, layer_name) {
  initial_dims <- dim(incidence)

  row_degrees <- rowSums(incidence)
  col_degrees <- colSums(incidence)

  zero_rows <- which(row_degrees == 0)
  zero_cols <- which(col_degrees == 0)

  zero_row_names <- if (length(zero_rows) > 0) rownames(incidence)[zero_rows] else character(0)
  zero_col_names <- if (length(zero_cols) > 0) colnames(incidence)[zero_cols] else character(0)

  if (length(zero_rows) > 0) {
    incidence <- incidence[-zero_rows, , drop = FALSE]
  }
  if (length(zero_cols) > 0) {
    incidence <- incidence[, -zero_cols, drop = FALSE]
  }

  final_dims <- dim(incidence)

  removal_summary <- list(
    layer = layer_name,
    initial_dims = initial_dims,
    final_dims = final_dims,
    zero_rows_removed = length(zero_rows),
    zero_cols_removed = length(zero_cols),
    zero_row_names = zero_row_names,
    zero_col_names = zero_col_names
  )

  return(list(incidence = incidence, removal_summary = removal_summary))
}

# Compute modularity with error handling - EXACTLY matches main function parameters
compute_modularity_safe <- function(incidence, seed = NULL) {
  if (!is.null(seed)) set.seed(seed)
  # Minimal, version-stable signature; avoids failures seen with extra args
  result <- tryCatch(
    bipartite::computeModules(incidence, method = "Beckett", deep = FALSE, deleteOriginalFiles = TRUE),
    error = function(e) {
      message("computeModules failed with error: ", e$message)
      NULL
    }
  )
  result
}

# Extract Q value from bipartite result
extract_Q_value <- function(module_result) {
  if (is.null(module_result)) return(NA_real_)
  Q <- tryCatch({
    if (isS4(module_result) && "likelihood" %in% slotNames(module_result)) {
      as.numeric(slot(module_result, "likelihood"))
    } else if (!is.null(module_result$likelihood)) {
      as.numeric(module_result$likelihood)
    } else {
      NA_real_
    }
  }, error = function(e) NA_real_)
  return(Q)
}

# Compute ARI between partitions
# Helper function to compute ARI between partitions (kept for potential future use)
compute_partition_ari <- function(partition1, partition2) {
  if (length(partition1) != length(partition2)) {
    return(NA_real_)
  }
  return(as.numeric(mclust::adjustedRandIndex(partition1, partition2)))
}

# Define compute_null_stability function (was missing!)
compute_null_stability <- function(null_matrix, n_stability_reps = 3, base_seed = NULL) {
  if (is.null(null_matrix) || sum(null_matrix) == 0) {
    return(list(n_valid = 0, CV = NA_real_, mean_ARI = NA_real_))
  }
  
  stability_q_values <- numeric(n_stability_reps)
  
  for (rep in 1:n_stability_reps) {
    seed <- if (!is.null(base_seed)) base_seed + rep else NULL
    mod_result <- compute_modularity_safe(null_matrix, seed = seed)
    q_val <- extract_Q_value(mod_result)
    stability_q_values[rep] <- if (!is.na(q_val)) q_val else NA_real_
  }
  
  valid_q <- stability_q_values[!is.na(stability_q_values)]
  
  return(list(
    n_valid = length(valid_q),
    CV = ifelse(length(valid_q) > 1, sd(valid_q) / mean(valid_q), NA_real_),
    mean_ARI = NA_real_  # ARI calculation omitted for efficiency
  ))
}


# Build a robust statistic function for oecosimu that restores dimnames, binarizes
mk_modularity_stat <- function(row_names, col_names) {
  force(row_names); force(col_names)
  function(x) {
    m <- as.matrix(x)
    storage.mode(m) <- "double"
    m <- (m > 0) * 1
    dimnames(m) <- list(row_names, col_names)
    # Skip degenerate cases early
    if (any(rowSums(m) == 0) || any(colSums(m) == 0)) return(NA_real_)
    res <- tryCatch(compute_modularity_safe(m, seed = NULL), error = function(e) NULL)
    extract_Q_value(res)
  }
}


# -----------------------------
# Command line argument parsing
# -----------------------------
args <- commandArgs(trailingOnly = TRUE)

# Parse layer arguments
layer_args <- args[!args %in% c("--pilot", "--final")]
param_args <- args[args %in% c("--pilot", "--final")]

if (length(layer_args) == 0) {
  run_both <- TRUE
  target_layer <- NULL
} else if (length(layer_args) == 1 && layer_args[1] %in% c("production", "utilization")) {
  run_both <- FALSE
  target_layer <- layer_args[1]
} else {
  stop("Usage: Rscript 03c_null_model_modularity.R [--layer production|utilization] [--pilot|--final]")
}

layers_to_run <- if (run_both) c("production", "utilization") else target_layer

# -----------------------------
# Directory setup
# -----------------------------
safe_dir_create("scripts/phase_04_topology/debug/logs")

cat("=== Phase 04 - Step 03c: Layer-Specific Null Model Modularity Test ===\n")
cat(paste("Timestamp:", timestamp(), "\n"))
cat(sprintf("Layers to test: %s\n", paste(layers_to_run, collapse = ", ")))

# -----------------------------
# Load parameters from manifest
# -----------------------------
manifest_json <- "docs/phase_04/parameters_manifest.json"
manifest <- list()
if (file.exists(manifest_json)) {
  manifest <- tryCatch(fromJSON(manifest_json), error = function(e) {
    message("Could not parse manifest JSON; using defaults")
    list()
  })
}

master_seed <- if (!is.null(manifest$master_seed)) manifest$master_seed else 2025

# Parameter selection: allow pilot vs final null model runs
use_final_params <- "--final" %in% param_args
use_pilot_params <- "--pilot" %in% param_args

# Default: use pilot parameters for quick testing
if (use_final_params) {
  n_nulls <- if (!is.null(manifest$null_model_N[["final"]])) manifest$null_model_N[["final"]] else 1000
  param_mode <- "final (full inference)"
} else if (use_pilot_params) {
  n_nulls <- if (!is.null(manifest$null_model_N[["pilot"]])) manifest$null_model_N[["pilot"]] else 100
  param_mode <- "pilot (quick testing)"
} else {
  # Default to pilot for debugging, but inform user
  n_nulls <- if (!is.null(manifest$null_model_N[["pilot"]])) manifest$null_model_N[["pilot"]] else 100
  param_mode <- "pilot (default - use --pilot or --final to specify)"
}

cat(sprintf("Parameters: master_seed=%d, n_nulls=%d (%s)\n", master_seed, n_nulls, param_mode))

# -----------------------------
# Load and validate inputs
# -----------------------------
cat("Loading adjacency matrices...\n")

required_files <- list(
  adj_prod_fg = "data/interim/adj_production_FG_agentsxpyov_conservative.rds",
  adj_util_fg = "data/interim/adj_utilization_FG_pyovxagents_conservative.rds"
)

for (name in names(required_files)) {
  if (!file.exists(required_files[[name]])) {
    stop("Required input missing: ", required_files[[name]])
  }
}

adj_prod_fg <- readRDS(required_files$adj_prod_fg)
adj_util_fg <- readRDS(required_files$adj_util_fg)

# -----------------------------
# Process each layer
# -----------------------------
all_results <- list()

for (layer in layers_to_run) {
  cat(sprintf("\n=== Testing %s layer ===\n", stringr::str_to_title(layer)))

  layer_start_time <- Sys.time()

  # 1. Build and filter incidence matrix
  cat("Building incidence matrix...\n")
  incidence_raw <- build_layer_incidence(adj_prod_fg, adj_util_fg, layer)
  filtered_result <- remove_zero_degree(incidence_raw, layer)
  incidence <- filtered_result$incidence
  removal_summary <- filtered_result$removal_summary

  if (sum(incidence) == 0) {
    cat("Warning: No interactions in filtered matrix. Skipping layer.\n")
    all_results[[layer]] <- list(
      layer = layer,
      status = "failed",
      reason = "no_interactions",
      removal_summary = removal_summary
    )
    next
  }

  cat(sprintf(
    "Matrix: %d × %d (%d interactions, %.1f%% fill)\n",
    nrow(incidence), ncol(incidence),
    sum(incidence), 100 * sum(incidence) / (nrow(incidence) * ncol(incidence))
  ))

  # 2. Load observed modularity from existing results (avoid redundant computation)
  cat("Loading pre-computed observed modularity...\n")

  replicate_q_file <- paste0("results/phase_04/modularity/replicate_Q_", layer, ".csv")
  summary_file <- "docs/phase_04/logs/step03_modularity_summary.txt"

  obs_Q <- NA_real_
  obs_stability <- NULL

  # Prefer representative Q from summary (matches main method)
  if (file.exists(summary_file)) {
    lines <- readLines(summary_file, warn = FALSE)
    anchor <- paste0(stringr::str_to_title(layer), " Layer:")
    idx <- which(trimws(lines) == anchor)
    if (length(idx) > 0) {
      # Search a small window after anchor for "Representative Q:"
      win <- lines[seq(idx[1], min(length(lines), idx[1] + 10))]
      rep_line <- grep("Representative Q:\\s*", win, value = TRUE)
      if (length(rep_line) > 0) {
        num <- sub(".*Representative Q: \\s*([0-9.]+).*", "\\1", rep_line[1])
        num_val <- suppressWarnings(as.numeric(num))
        if (!is.na(num_val)) {
          obs_Q <- num_val
          cat(sprintf("  Representative Q from summary: %.4f\n", obs_Q))
        }
      }
    }
  }

  if (is.na(obs_Q) && file.exists(replicate_q_file)) {
    cat("  Using replicate Q CSV: computing median Q to approximate representative\n")
    replicate_q_df <- read.csv(replicate_q_file, stringsAsFactors = FALSE)
    valid_q_values <- replicate_q_df$Q_value[!is.na(replicate_q_df$Q_value)]
    if (length(valid_q_values) > 0) {
      obs_Q <- stats::median(valid_q_values)
    }
    obs_stability <- list(
      n_valid = length(valid_q_values),
      mean_Q = mean(valid_q_values),
      sd_Q = sd(valid_q_values),
      CV = ifelse(mean(valid_q_values) > 0, sd(valid_q_values) / mean(valid_q_values), NA_real_),
      mean_ARI = NA_real_,
      ari_iqr_lower = NA_real_,
      ari_iqr_upper = NA_real_
    )
    cat(sprintf("  Loaded %d pre-computed Q values (median Q=%.4f)\n", length(valid_q_values), obs_Q))
    cat(sprintf(
      "Observed stability: mean_Q=%.4f, sd=%.4f, CV=%.4f (%d valid)\n",
      obs_stability$mean_Q, obs_stability$sd_Q, obs_stability$CV, obs_stability$n_valid
    ))
  }

  if (!is.na(obs_Q) && is.null(obs_stability)) {
    if (file.exists(replicate_q_file)) {
      replicate_q_df <- read.csv(replicate_q_file, stringsAsFactors = FALSE)
      valid_q_values <- replicate_q_df$Q_value[!is.na(replicate_q_df$Q_value)]
      obs_stability <- list(
        n_valid = length(valid_q_values),
        mean_Q = if (length(valid_q_values) > 0) mean(valid_q_values) else obs_Q,
        sd_Q = if (length(valid_q_values) > 1) sd(valid_q_values) else NA_real_,
        CV = if (length(valid_q_values) > 1 && mean(valid_q_values) > 0) sd(valid_q_values) / mean(valid_q_values) else NA_real_,
        mean_ARI = NA_real_,
        ari_iqr_lower = NA_real_,
        ari_iqr_upper = NA_real_
      )
    } else {
      obs_stability <- list(
        n_valid = 1,
        mean_Q = obs_Q,
        sd_Q = NA_real_,
        CV = NA_real_,
        mean_ARI = NA_real_,
        ari_iqr_lower = NA_real_,
        ari_iqr_upper = NA_real_
      )
    }
  }

  if (is.na(obs_Q)) {
    # Fallback: compute single observed modularity if files don't exist
    cat("  No existing results found - computing single observed modularity\n")
    obs_result <- compute_modularity_safe(incidence, seed = master_seed)
    obs_Q <- extract_Q_value(obs_result)

    obs_stability <- list(
      n_valid = 1,
      mean_Q = obs_Q,
      sd_Q = NA_real_,
      CV = NA_real_,
      mean_ARI = NA_real_,
      ari_iqr_lower = NA_real_,
      ari_iqr_upper = NA_real_
    )

    cat(sprintf("Observed Q: %.4f (computed)\n", obs_Q))
  }

  if (is.na(obs_Q)) {
    cat("Warning: Could not determine observed modularity. Skipping layer.\n")
    all_results[[layer]] <- list(
      layer = layer,
      status = "failed",
      reason = "obs_Q_failed",
      removal_summary = removal_summary
    )
    next
  }

  # 4. Generate null models using per-null oecosimu calls (like 04a), no reseeding inside stat
  cat(sprintf("Generating %d nulls via vegan::oecosimu (curveball)...\n", n_nulls))
  stat_fun <- mk_modularity_stat(rownames(incidence), colnames(incidence))
  null_Q_values <- rep(NA_real_, n_nulls)
  fail_counts <- list(oeco_error = 0L, stat_na = 0L)
  for (i in seq_len(n_nulls)) {
    if (i == 1 || i %% max(1, floor(n_nulls / 10)) == 0) cat(sprintf("  ... null %d/%d\n", i, n_nulls))
    set.seed(master_seed + 4242 + i)
    single_result <- tryCatch({
      vegan::oecosimu(incidence,
                      nestfun = stat_fun,
                      method = "curveball",
                      nsimul = 2,
                      alternative = "two.sided")
    }, error = function(e) NULL)
    if (is.null(single_result) || is.null(single_result$oecosimu$simulated)) {
      fail_counts$oeco_error <- fail_counts$oeco_error + 1L
      next
    }
    qv <- suppressWarnings(as.numeric(single_result$oecosimu$simulated[1]))
    if (is.finite(qv)) null_Q_values[i] <- qv else fail_counts$stat_na <- fail_counts$stat_na + 1L
  }

  # Remove NA values for analysis
  null_Q_clean <- null_Q_values[!is.na(null_Q_values)]

  if (length(null_Q_clean) < 5) {
    cat("Warning: Too few valid null Q values. Skipping layer.\n")
    all_results[[layer]] <- list(
      layer = layer,
      status = "failed",
      reason = "insufficient_nulls",
      removal_summary = removal_summary,
      obs_Q = obs_Q,
      valid_nulls = 0
    )
    next
  }

  # 5a. Assess null distribution stability on sample of null matrices (memory-efficient)
  # Assess null distribution stability (approximate via chunk CV if enough sims)
  cat("Assessing null distribution stability...\n")
  if (length(null_Q_clean) >= 10) {
    half <- floor(length(null_Q_clean) / 2)
    null_cv_mean <- suppressWarnings(sd(null_Q_clean, na.rm = TRUE) / mean(null_Q_clean, na.rm = TRUE))
    null_ari_mean <- NA_real_
  } else {
    null_cv_mean <- NA_real_
    null_ari_mean <- NA_real_
  }

  # 5. Compute null statistics
  # Null summary statistics
  null_mean <- mean(null_Q_clean)
  null_sd <- sd(null_Q_clean)
  null_min <- min(null_Q_clean)
  null_max <- max(null_Q_clean)

  # Compute p-value (two-tailed for comprehensive significance testing)
  # More robust approach for biological network analysis
  null_ge_obs <- sum(null_Q_clean >= obs_Q)
  null_le_obs <- sum(null_Q_clean <= obs_Q)

  # Two-tailed p-value with +1 correction
  p_value_twotailed <- 2 * min(
    (null_ge_obs + 1) / (length(null_Q_clean) + 1),
    (null_le_obs + 1) / (length(null_Q_clean) + 1)
  )

  # Also report one-tailed p-value for completeness
  p_value_onetail_higher <- (null_ge_obs + 1) / (length(null_Q_clean) + 1) # Higher than expected
  p_value_onetail_lower <- (null_le_obs + 1) / (length(null_Q_clean) + 1) # Lower than expected

  # Compute SES
  ses <- (obs_Q - null_mean) / null_sd

  # Independence check (split nulls in half)
  independence_check <- "insufficient_nulls"
  if (length(null_Q_clean) >= 20) {
    n_half <- length(null_Q_clean) %/% 2
    first_half <- null_Q_clean[1:n_half]
    second_half <- null_Q_clean[(n_half + 1):length(null_Q_clean)]
    mean_diff <- abs(mean(first_half) - mean(second_half))
    if (mean_diff < 0.01) {
      independence_check <- "passed"
    } else {
      independence_check <- sprintf("warning (diff=%.3f)", mean_diff)
    }
  }

  cat(sprintf(
    "Null results: mean=%.4f±%.4f, range=%.4f-%.4f, p_twotailed=%.4f, p_onetail(higher)=%.4f, SES=%.2f\n",
    null_mean, null_sd, null_min, null_max, p_value_twotailed, p_value_onetail_higher, ses
  ))
  cat(sprintf("Null independence: %s (%d valid nulls)\n", independence_check, length(null_Q_clean)))
  if (!is.na(null_cv_mean)) {
    cat(sprintf("Null stability: CV=%.3f, mean_ARI=%.3f\n", null_cv_mean, null_ari_mean))
  }

  # 6. Store results
  layer_end_time <- Sys.time()
  layer_elapsed <- as.numeric(difftime(layer_end_time, layer_start_time, units = "secs"))

  all_results[[layer]] <- list(
    layer = layer,
    status = "success",
    removal_summary = removal_summary,
    incidence_dims = dim(incidence),
    incidence_fill = sum(incidence) / (nrow(incidence) * ncol(incidence)),
    obs_Q = obs_Q,
    obs_stability = obs_stability,
    null_mean = null_mean,
    null_sd = null_sd,
    null_min = null_min,
    null_max = null_max,
    p_value_twotailed = p_value_twotailed,
    p_value_onetail_higher = p_value_onetail_higher,
    p_value_onetail_lower = p_value_onetail_lower,
    ses = ses,
    valid_nulls = length(null_Q_clean),
    independence_check = independence_check,
    null_stability_cv = null_cv_mean,
    null_stability_ari = null_ari_mean,
    n_nulls_requested = n_nulls,
    elapsed_sec = layer_elapsed
  )

  cat(sprintf("Layer %s completed in %.2f seconds\n", layer, layer_elapsed))
}

# -----------------------------
# Generate consolidated summary
# -----------------------------
cat("\nGenerating consolidated summary...\n")

summary_lines <- c(
  "Phase 04 - Step 03c: Layer-Specific Null Model Modularity Test Summary",
  paste("Timestamp:", timestamp()),
  paste("Master seed:", master_seed),
  paste("Nulls per layer:", n_nulls),
  "",
  "Method:",
  "  Null generation: vegan::nullmodel + simulate(method = 'curveball')",
  "  Modularity: bipartite::computeModules (Beckett method - same as main function)",
  "  Statistical testing: two-tailed empirical with +1 correction",
  "  Stability assessment: CV and ARI metrics for both observed and null distributions",
  "  SES: (observed - null_mean) / null_sd",
  ""
)

# Add layer-specific results
for (layer in names(all_results)) {
  result <- all_results[[layer]]

  summary_lines <- c(
    summary_lines,
    paste(stringr::str_to_title(layer), "Layer:"),
    paste("  Status:", result$status)
  )

  if (result$status == "success") {
    summary_lines <- c(
      summary_lines,
      sprintf(
        "  Matrix: %d × %d (%.1f%% fill)",
        result$incidence_dims[1], result$incidence_dims[2],
        100 * result$incidence_fill
      ),
      sprintf(
        "  Nodes removed: %d FGs, %d PYOVs",
        result$removal_summary$zero_rows_removed,
        result$removal_summary$zero_cols_removed
      ),
      sprintf("  Observed Q: %.4f", result$obs_Q),
      sprintf(
        "  Observed stability: mean=%.4f, sd=%.4f, CV=%.4f, mean_ARI=%.4f (%d valid)",
        result$obs_stability$mean_Q, result$obs_stability$sd_Q,
        result$obs_stability$CV, result$obs_stability$mean_ARI,
        result$obs_stability$n_valid
      ),
      sprintf(
        "  Null distribution: mean=%.4f±%.4f, range=%.4f-%.4f",
        result$null_mean, result$null_sd, result$null_min, result$null_max
      ),
      sprintf(
        "  Statistical test: p_twotailed=%.4f, p_onetail(higher)=%.4f, SES=%.2f",
        result$p_value_twotailed, result$p_value_onetail_higher, result$ses
      ),
      sprintf(
        "  Significance: %s",
        ifelse(result$p_value_twotailed < 0.05, "SIGNIFICANT", "Not significant")
      ),
      sprintf(
        "  Independence: %s (%d valid nulls)",
        result$independence_check, result$valid_nulls
      ),
      sprintf(
        "  Null stability: CV=%.3f, ARI=%.3f",
        ifelse(is.na(result$null_stability_cv), "NA", result$null_stability_cv),
        ifelse(is.na(result$null_stability_ari), "NA", result$null_stability_ari)
      ),
      sprintf("  Runtime: %.2f seconds", result$elapsed_sec)
    )

    # Interpretation guidance
    if (result$ses > 2) {
      summary_lines <- c(summary_lines, "  Interpretation: Strong positive deviation (more modular than expected)")
    } else if (result$ses < -2) {
      summary_lines <- c(summary_lines, "  Interpretation: Strong negative deviation (less modular than expected)")
    } else {
      summary_lines <- c(summary_lines, "  Interpretation: Within expected range given degree constraints")
    }
  } else {
    summary_lines <- c(
      summary_lines,
      paste("  Reason:", result$reason)
    )
  }

  summary_lines <- c(summary_lines, "")
}

# Add general interpretation notes
summary_lines <- c(
  summary_lines,
  "Interpretation Guidelines:",
  "  SES > 2: Strong positive deviation (more modular than expected)",
  "  SES < -2: Strong negative deviation (less modular than expected)",
  "  |SES| < 2: Within expected range given degree constraints",
  "  p_twotailed < 0.05: Statistically significant deviation",
  "  Null CV > 0.10: High variability in null modularity estimates",
  "  Null mean ARI < 0.60: Low consistency in null partitions",
  "",
  "Notes:",
  "  - Null models preserve layer-specific degree sequences via vegan curveball swaps",
  "  - curveball swaps generated via vegan::nullmodel + simulate (batch)",
  "  - Algorithm parameters EXACTLY match main function for valid comparison",
  "  - Stability assessed on samples of null matrices using replicates",
  "  - Two-tailed testing more appropriate for comprehensive biological analysis",
  "  - Results are for FG-level networks only",
  "",
  "Output saved to: scripts/phase_04_topology/debug/logs/03c_null_modularity_summary.txt"
)

# Write summary
summary_file <- "scripts/phase_04_topology/debug/logs/03c_null_modularity_summary.txt"
writeLines(summary_lines, summary_file)

# Save session info
session_file <- "scripts/phase_04_topology/debug/logs/03c_null_session_info.txt"
writeLines(capture.output(sessionInfo()), session_file)

# Display summary
cat("\n", paste(summary_lines, collapse = "\n"), "\n")

cat("\n=== Null Model Modularity Test Complete ===\n")
cat(sprintf("Summary saved to: %s\n", summary_file))
cat(sprintf("Session info saved to: %s\n", session_file))
cat("Note: Compact mode - only text summaries saved (no RDS/figures)\n")
