#!/usr/bin/env Rscript

# Step 2: Pyoverdine Index Mapping and Node Dictionary
# Creates a contiguous pyoverdine index mapping (matrix_index 1..n_validated)
# and persists nodes_pyoverdines_conservative.{rds,csv}
#
# Expectations:
# - Uses validated pyoverdine groups inferred from pairing / receptor->pyov lookup
# - If FG/strain node files exist, compute `active_production` and `active_utilization`
#   flags; otherwise leave them NA and print a note.
#
# Usage:
#   Rscript scripts/phase_03_network/02_pyov_index_mapping.R
#
# Author: automated assistant (created for Phase 3)
# Date: autogenerated

suppressPackageStartupMessages({
  library(dplyr)
  library(purrr)
  library(readr)
  library(tidyr)
})

# -------------------------
# Helper: safe readRDS paths
# -------------------------
safe_read_rds <- function(paths) {
  for (p in paths) {
    if (file.exists(p)) {
      message("Reading: ", p)
      return(readRDS(p))
    }
  }
  stop("None of the provided paths exist:\n", paste(paths, collapse = "\n"))
}

# -------------------------
# Input candidate paths
# -------------------------
# Pairing / receptor->pyov results could be in different locations depending on earlier steps.
receptor_to_pyov_paths <- c(
  "data/interim/receptor_to_pyoverdine.rds",
  "data/interim/rds/receptor_to_pyoverdine.rds",
  "data/interim/rds/receptor_to_pyov.rds"
)

pairing_paths <- c(
  "data/interim/rds/pairing_result.rds",
  "data/interim/rair/pairing_result.rds", # kept for defensive coding
  "data/interim/pairing_result.rds"
)

# Node files produced by Step 1
fg_nodes_paths <- c(
  "data/interim/nodes_functional_groups_conservative.rds",
  "data/interim/nodes_functional_groups_conservative.rds"
)
strain_nodes_paths <- c(
  "data/interim/nodes_strains_conservative.rds",
  "data/interim/nodes_strains_conservative.rds"
)

# Output paths
out_rds <- "data/interim/nodes_pyoverdines_conservative.rds"
out_csv <- "data/interim/nodes_pyoverdines_conservative.csv"
docs_dir <- "docs/phase_03"
dir.create("data/interim", showWarnings = FALSE, recursive = TRUE)
dir.create(docs_dir, showWarnings = FALSE, recursive = TRUE)

# -------------------------
# Determine validated pyoverdine groups
# -------------------------
validated_pyovs <- NULL
validated_source <- NULL

# Try receptor_to_pyov first (this is an expanded mapping with pyoverdine_group column)
if (any(file.exists(receptor_to_pyov_paths))) {
  receptor_to_pyov <- safe_read_rds(receptor_to_pyov_paths)
  # Expect a tibble/data.frame with column 'pyoverdine_group'
  if ("pyoverdine_group" %in% colnames(receptor_to_pyov)) {
    validated_pyovs <- sort(unique(as.integer(unlist(receptor_to_pyov$pyoverdine_group))))
    validated_source <- "receptor_to_pyoverdine"
  } else {
    # Try to find a plausible column
    candidate_cols <- colnames(receptor_to_pyov)
    stop("Loaded receptor_to_pyoverdine but no 'pyoverdine_group' column found. Columns: ",
         paste(candidate_cols, collapse = ", "))
  }
}

# Fallback: try pairing_result (we extract column 1 which contains synthetase groups)
if (is.null(validated_pyovs) && any(file.exists(pairing_paths))) {
  pairing_raw <- safe_read_rds(pairing_paths)
  # pairing is expected to be a matrix-like object with rows representing pairs
  # Column 1 contains synthetase/pyov group lists
  if (is.matrix(pairing_raw) || is.data.frame(pairing_raw)) {
    # attempt to unwrap first column
    pyov_list <- lapply(seq_len(nrow(pairing_raw)), function(i) {
      cell <- pairing_raw[i, 1][[1]]
      if (is.list(cell)) cell <- unlist(cell)
      as.integer(cell)
    })
    validated_pyovs <- sort(unique(unlist(pyov_list)))
    validated_source <- "pairing_result"
  } else {
    stop("pairing_result found but unexpected structure. Expect matrix/data.frame.")
  }
}

if (is.null(validated_pyovs)) {
  stop("Could not locate validated pyoverdine groups. Make sure pairing/receptor->pyov outputs exist.")
}

message("Validated pyoverdine groups loaded from: ", validated_source)
message("Number of validated pyoverdine groups:", length(validated_pyovs))

# Create contiguous indexing (matrix_index) and node_id labels
n_pyovs <- length(validated_pyovs)
pyov_df <- tibble(
  original_pyov_id = as.integer(validated_pyovs)
) %>%
  arrange(original_pyov_id) %>%
  mutate(
    matrix_index = seq_len(n()),
    node_id = sprintf("PYO_%02d", matrix_index),
    label = paste0("pyov_", original_pyov_id),
    # placeholders to be filled: active_production, active_utilization
    active_production = NA,
    active_utilization = NA,
    notes = NA_character_
  )

# -------------------------
# Attempt to compute active flags if FG / strain nodes exist
# -------------------------
fg_nodes_present <- any(file.exists(fg_nodes_paths))
strain_nodes_present <- any(file.exists(strain_nodes_paths))

if (fg_nodes_present) {
  fg_nodes <- safe_read_rds(fg_nodes_paths)
  # Expect fg_nodes to have `validated_production_set` and `usable_pyoverdine_set` list-columns
  if (!("validated_production_set" %in% colnames(fg_nodes)) ||
      !("usable_pyoverdine_set" %in% colnames(fg_nodes))) {
    warning("FG node table found but missing expected columns (`validated_production_set`, `usable_pyoverdine_set`).")
  } else {
    fg_prod_pyovs <- sort(unique(unlist(fg_nodes$validated_production_set)))
    fg_util_pyovs <- sort(unique(unlist(fg_nodes$usable_pyoverdine_set)))
    message("FG-level pyov in production (unique): ", length(fg_prod_pyovs))
    message("FG-level pyov in utilization (unique): ", length(fg_util_pyovs))
    # mark active flags for pyovs contained in FG nodes
    pyov_df <- pyov_df %>%
      mutate(
        active_production = original_pyov_id %in% fg_prod_pyovs,
        active_utilization = original_pyov_id %in% fg_util_pyovs,
        notes = ifelse(is.na(notes), "active flags from FG nodes", notes)
      )
  }
}

if (!fg_nodes_present && strain_nodes_present) {
  message("FG node table not found; trying strain node table to infer activity.")
}

if (strain_nodes_present) {
  strain_nodes <- safe_read_rds(strain_nodes_paths)
  # Expect strain_nodes list columns: validated_production_set, usable_pyoverdine_set OR similarly named columns
  prod_col <- if ("validated_production_set" %in% colnames(strain_nodes)) "validated_production_set" else NULL
  util_col <- if ("usable_pyoverdine_set" %in% colnames(strain_nodes)) "usable_pyoverdine_set" else NULL

  if (is.null(prod_col) && is.null(util_col)) {
    warning("Strain node table found but missing validated_production_set and usable_pyoverdine_set columns.")
  } else {
    prod_pyovs_strain <- if (!is.null(prod_col)) sort(unique(unlist(strain_nodes[[prod_col]]))) else integer(0)
    util_pyovs_strain <- if (!is.null(util_col)) sort(unique(unlist(strain_nodes[[util_col]]))) else integer(0)
    message("Strain-level pyov in production (unique): ", length(prod_pyovs_strain))
    message("Strain-level pyov in utilization (unique): ", length(util_pyovs_strain))

    # Update active flags: if previously NA, set from strain-level; otherwise OR with existing
    pyov_df <- pyov_df %>%
      mutate(
        active_production = ifelse(is.na(active_production),
                                   original_pyov_id %in% prod_pyovs_strain,
                                   active_production | (original_pyov_id %in% prod_pyovs_strain)),
        active_utilization = ifelse(is.na(active_utilization),
                                    original_pyov_id %in% util_pyovs_strain,
                                    active_utilization | (original_pyov_id %in% util_pyovs_strain)),
        notes = ifelse(is.na(notes), "active flags from strain nodes", notes)
      )
  }
}

# If neither present or flags still NA, leave as NA but warn
if (all(is.na(pyov_df$active_production)) && all(is.na(pyov_df$active_utilization))) {
  message("Active production/utilization flags could not be inferred (FG and strain node tables not found or missing expected columns).")
  message("Flags are left as NA; they will be filled after adjacency construction.")
}

# -------------------------
# Additional columns: active counts if possible
# -------------------------
# If FG nodes present, compute counts per pyov of how many FGs produce / utilize
if (exists("fg_nodes") && ("validated_production_set" %in% colnames(fg_nodes))) {
  prod_counts <- table(unlist(lapply(fg_nodes$validated_production_set, function(x) as.integer(x))))
  util_counts <- table(unlist(lapply(fg_nodes$usable_pyoverdine_set, function(x) as.integer(x))))
  pyov_df <- pyov_df %>%
    mutate(
      fg_production_count = as.integer(prod_counts[as.character(original_pyov_id)] %>% replace_na(0)),
      fg_utilization_count = as.integer(util_counts[as.character(original_pyov_id)] %>% replace_na(0))
    )
} else {
  pyov_df <- pyov_df %>%
    mutate(fg_production_count = NA_integer_, fg_utilization_count = NA_integer_)
}

# If strain nodes present, compute counts per pyov of how many strains produce / utilize
if (exists("strain_nodes") && ("validated_production_set" %in% colnames(strain_nodes))) {
  prod_counts_str <- table(unlist(lapply(strain_nodes$validated_production_set, function(x) as.integer(x))))
  util_counts_str <- table(unlist(lapply(strain_nodes$usable_pyoverdine_set, function(x) as.integer(x))))
  pyov_df <- pyov_df %>%
    mutate(
      strain_production_count = as.integer(prod_counts_str[as.character(original_pyov_id)] %>% replace_na(0)),
      strain_utilization_count = as.integer(util_counts_str[as.character(original_pyov_id)] %>% replace_na(0))
    )
} else {
  pyov_df <- pyov_df %>%
    mutate(strain_production_count = NA_integer_, strain_utilization_count = NA_integer_)
}

# -------------------------
# Save outputs
# -------------------------
message("Saving pyoverdine node dictionary to: ", out_rds, " and ", out_csv)
saveRDS(pyov_df, out_rds)
# Ensure plain CSV with simple columns for humans
pyov_csv <- pyov_df %>%
  select(original_pyov_id, matrix_index, node_id, label,
         active_production, active_utilization,
         fg_production_count, fg_utilization_count,
         strain_production_count, strain_utilization_count, notes)
write_csv(pyov_csv, out_csv)

# Summary report
summary_lines <- c(
  sprintf("Step 2: Pyoverdine index mapping created at %s", Sys.time()),
  sprintf("Source of validated pyovs: %s", validated_source),
  sprintf("Validated pyov count (n): %d", n_pyovs),
  sprintf("Output RDS: %s", out_rds),
  sprintf("Output CSV: %s", out_csv),
  "",
  "Active flags:",
  paste0("  - active_production: ", sum(pyov_df$active_production %in% TRUE, na.rm = TRUE),
         " TRUE, ", sum(is.na(pyov_df$active_production)), " NA"),
  paste0("  - active_utilization: ", sum(pyov_df$active_utilization %in% TRUE, na.rm = TRUE),
         " TRUE, ", sum(is.na(pyov_df$active_utilization)), " NA"),
  "",
  "Notes: fg/strain counts per pyov persisted where available."
)

writeLines(summary_lines, file.path(docs_dir, "pyov_index_mapping_summary.txt"))
message(paste(summary_lines, collapse = "\n"))

# Save session info for provenance
writeLines(capture.output(sessionInfo()), file.path(docs_dir, "session_info_pyov_index.txt"))

invisible(NULL)
